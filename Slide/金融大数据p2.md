% 金融大数据-实验二
% 田昊东
% 2023/11/23

## MapReduce编程环境

#### 使用idea远程连接hadoop

- 下载和虚拟机版本相同的hadoop安装包解压放在英文路径，并添加到HADOOP_HOME
- HADOOP_USER_NAME设置hadoop用户名
- 将hadoop的/bin路径添加到path变量
- 下载补充文件（3.0.0就行）[steveloughran/winutils: Windows binaries for Hadoop versions (built from the git commit ID used for the ASF relase) (github.com)](https://github.com/steveloughran/winutils)
  - 将hadoop.dll添加到C:\Windows\System32
  - 用下载的bin替换原先的

---

### idea下载bigdata插件

- 连接hadoop
- <img src="https://thdlrt.oss-cn-beijing.aliyuncs.com/image-20231018141000967.png" alt="image-20231018141000967" style="zoom: 33%;" />
- url使用集群/虚拟机ip
- 勾选启用隧道并配置ssh（连接虚拟机）

---

### 连接hdfs

- 地址为ip+端口
- <img src="https://thdlrt.oss-cn-beijing.aliyuncs.com/image-20231018154459089.png" alt="image-20231018154459089" style="zoom: 33%;" />
- connectionError
  - 在`core-site.xml`文件中更改`fs.defaultFS`属性的值为Linux服务器的IP地址，例如hdfs://192.168.1.100:9000，然后**重启Hadoop服务**以使更改生效。

---

- 将hadoop的两个xml文件拷贝到resources文件夹

  - <img src="https://thdlrt.oss-cn-beijing.aliyuncs.com/image-20231018165101484.png" alt="image-20231018165101484" style="zoom: 50%;" />

  - 同时新建`log4j`配置文件

    - ```properties
      # Root logger option
      log4j.rootLogger=INFO, stdout
      
      # Redirect log messages to console
      log4j.appender.stdout=org.apache.log4j.ConsoleAppender
      log4j.appender.stdout.Target=System.out
      log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
      log4j.appender.stdout.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n
      
      ```

---

- 更改`pom.xml`（仅供参考,我使用的jdk11）

  - ```xml
    <?xml version="1.0" encoding="UTF-8"?>
    <project xmlns="http://maven.apache.org/POM/4.0.0"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
        <modelVersion>4.0.0</modelVersion>
    
        <groupId>cn.lg</groupId>
        <artifactId>MergeFiles</artifactId>
        <version>1.0-SNAPSHOT</version>
    
        ...
    
    ```

    - 修改后要重新加载

---

- 配置运行文件（运行-编辑配置-创建maven）

  - <img src="https://thdlrt.oss-cn-beijing.aliyuncs.com/image-20231018165405067.png" alt="image-20231018165405067" style="zoom: 25%;" />
  - 运行参数`compile exec:java -Dexec.mainClass=org.example.MergeFiles "-Dexec.args=/user/hadoop/input /user/hadoop/output"`
    - 指出主类和输入输出路径

---

## T3-贷款违约检测模型

---

- 使用knn最邻近分类算法
- 将整个过程如下划分：
  - init：求出每一列的最大最小值，为后续的归一化做准备
  - maxmin：根据init求出的值，对非字符数据进行01归一化操作
  - div：8:2划分数据集得到训练集和测试集
  - knn：根据训练集对测试集进行预测得到结果
  - score：对预测结果进行分析并计算accuracy值

---

## Init

---

map

- 统计非字符列的所有取值

```java
    //掠过第一行
    if (key.get() == 0)
        return;
    List<String> line = new ArrayList<>(Arrays.asList(value.toString().split(",")));
    for (int i = 1; i < line.size() - 1; i++) {// 第一列是id，最后一列是结果，不处理
        try {
            double value1 = Double.parseDouble(line.get(i));
            context.write(new Text(i + ""), new DoubleWritable(value1));// 汇总每一列的所有取值
        } catch (NumberFormatException e) {
            ;// 字符数据，不处理
        }
    }
```

---

reduce

- 从可能的取值中找出最大最小值

```java
    protected void reduce(Text key, Iterable<DoubleWritable> values, Context context)
        throws IOException, InterruptedException {
        double max = Double.MIN_VALUE;
        double min = Double.MAX_VALUE;
        for (DoubleWritable value : values) {
            max = Math.max(max, value.get());
            min = Math.min(min, value.get());
        }
        context.write(key, new Text(min + "," + max));
    }
```

---

## maxmin

---

main

  - 需要传入上一次的统计结果`job_maxmin.addCacheFile(new Path(output_init+"/part-r-00000").toUri());`

---

setup(map)

- 读取文件，建立列号和最大最小值之间的映射

```java
//HashMap<Integer, Pair> minmax = new HashMap<>();

FileSystem fs = FileSystem.get(context.getConfiguration());
Path path = new Path(cacheFiles[0].toString());
BufferedReader reader = new BufferedReader(new InputStreamReader(fs.open(path)));
String line;//逐行读取
while ((line = reader.readLine()) != null) {
    String[] split = line.trim().split("\\s+");
    String[] split2 = split[1].split(",");
    minmax.put(Integer.parseInt(split[0]),
               new Pair(Double.parseDouble(split2[0]), Double.parseDouble(split2[1])));
}
reader.close();
```

---

map

- 根据建立的映射对所有非字符列进行归一化

```java
  List<String> line = new ArrayList<>(Arrays.asList(value.toString().split(",")));
  String res = "";
  for (int i = 1; i < line.size() - 1; i++) {
      try {
          double value1 = Double.parseDouble(line.get(i));
          Pair pair = minmax.get(i);
          double min = pair.min;
          double max = pair.max;
          double result = (value1 - min) / (max - min);
          res += "," + result;
      } catch (NumberFormatException e) {
          ;// 字符数据，不处理
      }
  }
  context.write(new Text(line.get(0) + res + "," + line.get(line.size() - 1)), new Text());
```

---

reduce

- 直接存储map的结果即可`context.write(key, new Text());`

---

## div

---

map

- 随机数流`static Iterator<Integer> iterator = new Random(47).ints(0, 100).boxed().iterator();`

- 每次取一个随机数，根据值决定key是train还是test，实现近似8:2划分

```java
    Integer random = iterator.next();
    if (random >= 80) {// 训练集
        context.write(new Text("test"), value);
    } else {
        context.write(new Text("train"), value);
    }
```

---

reduce

- 使用multipleOutputs实现将训练集和测试集分别写入到两个文件分别存储

```java
    static MultipleOutputs<Text, Text> multipleOutputs;
    @Override
    protected void setup(Context context) throws IOException, InterruptedException {
        multipleOutputs = new MultipleOutputs<>(context);
    }
    @Override
    protected void reduce(Text key, Iterable<Text> values, Context context)
        throws IOException, InterruptedException {
        for (Text value : values) {
            multipleOutputs.write(value, new Text(), key.toString());
        }
    }
    @Override
    protected void cleanup(Context context) throws IOException, InterruptedException {
        multipleOutputs.close();
    }
```

---

## knn

---

main

- 传入训练集`job_knn.addCacheFile(new Path(output_div+"/train-r-00000").toUri());`
- 训练集需要每个节点一份，用于在分类时进行比对
- 测试集作为map的输入

---

setup（map）

- 读取并缓存训练集

```java
    FileSystem fs = FileSystem.get(context.getConfiguration());
    Path path = new Path(cacheFiles[0].toString());
    BufferedReader reader = new BufferedReader(new InputStreamReader(fs.open(path)));
    String line;
    while ((line = reader.readLine()) != null) {
        String[] split = line.split(",");
        Double[] temp = new Double[split.length - 1];
        for (int i = 1; i < split.length; i++) {
            temp[i - 1] = Double.parseDouble(split[i]);
        }
        if(data.size()<MaxSize)
            data.add(temp);
    }
    reader.close();
```

---

优先队列

```java
    private PriorityQueue<Double[]> findNearestNeighbors(Double[] testFeatures) {
        PriorityQueue<Double[]> neighbors = new PriorityQueue<>(k, Comparator.comparingDouble(a -> distance(a, testFeatures)));
        for (Double[] trainData : data) {
            neighbors.offer(trainData);
            if (neighbors.size() > k) {
                neighbors.poll();
            }
        }
        return neighbors;
    }
```

- 维护与目标最为接近的k个条目

---

map

```java
// 计算距离并选取最近的k个邻居
PriorityQueue<Double[]> neighbors = findNearestNeighbors(features);
// 进行多数投票
int count0 = 0, count1 = 0;
for (int i = 0; i < k; i++) {
    Double[] neighbor = neighbors.poll();
    if (neighbor[neighbor.length - 1] - 0.0 < 1e-6) {
        count0++;//t投票
    } else {
        count1++;
    }
}
// 输出结果
context.write(new Text(id), new Text(count1 > count0 ? "1" : "0"));
```

---

reduce

- 直接存储map的结果`context.write(key,values.iterator().next());`

---

## score

---

main

- 传入含结果的测试集作为答案用于与预测结果进行比对
- `job_score.addCacheFile(new Path(output_div+"/test-r-00000").toUri());`

---

setup(map)

- 同理读取训练集数据，建立id-结果的映射
- `HashMap<Integer,Integer> res = new HashMap<>();`

---

map

- 读取预测结果并于训练集的结果进行比对

```java
String[] line = value.toString().split("\\s+");
int id = Integer.parseInt(line[0]);
int result = Integer.parseInt(line[line.length-1]);
int right = res.get(id);
if(result==right)
    context.write(new Text("res"),new Text("1"));
else
    context.write(new Text("res"),new Text("0"));
```

---

reduce

- 根据对正确和错误数目的统计计算出准确率

```java
for(Text value:values){
    if(value.toString().equals("1"))
        sum1++;
    else
        sum2++;
}
context.write(new Text("Accuracy"),new Text(sum1/(sum1+sum2)+""));
```

---

## 运行结果

<img src="https://thdlrt.oss-cn-beijing.aliyuncs.com/image-20231115144932948.png" alt="image-20231115144932948" style="zoom: 33%;" />

---

最终统计结果`Accuracy	0.9176155283034192`
每个步骤的详细输出再output文件夹下
<img src="https://thdlrt.oss-cn-beijing.aliyuncs.com/image-20231115145839906.png" alt="image-20231115145839906" style="zoom: 67%;" />
