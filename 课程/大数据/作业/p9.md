#### 简述Spark的技术特点

- 速度：Spark通过在内存中计算来优化迭代工作负载的执行速度，这比传统的基于磁盘的Hadoop MapReduce要快。
- 易于使用：Spark支持多种语言，如Scala、Java、Python和R，并提供了丰富的APIs，这使得构建并行应用程序更加容易。
- 高级分析：Spark不仅仅支持Map和Reduce操作，它还支持SQL查询、流数据处理、机器学习和图处理等高级数据分析技术。
- 灵活性：Spark能够处理批处理和实时流数据，提供了统一的数据处理平台。
- 可伸缩性：Spark利用了Hadoop的分布式文件系统（HDFS）的可伸缩性，它能够在数千个节点上扩展。
- 弹性计算：Spark的弹性分布式数据集（RDDs）是一个容错的、并行的数据结构，可以让用户显式地持久化数据到内存中，并在计算过程中复用，这在迭代算法和快速查询中非常有用。
- 内存计算：Spark的核心是内存计算，它能够极大地提升处理速度。Spark提出了一种基于内存的弹性分布式数据集(RDD)，通过对RDD的一系列操作完成计算任务，可以大大提高性能。

#### 简述Spark的基本构架组成

- <img src="https://thdlrt.oss-cn-beijing.aliyuncs.com/image-20231209233409206.png" alt="image-20231209233409206" style="zoom:50%;" />

- Master Node（主节点）：在集群部署时，Master Node充当控制器的角色，负责管理整个集群的正常运行，以及Worker Nodes的管理。

- Worker Node（工作节点）：作为计算节点，Worker Node接收Master Node的命令执行计算任务，并进行状态汇报。
- Executor（执行器）：Executor是在Worker Node上为每个Application启动的进程，它负责运行Task，将数据保存在内存或磁盘中，并将结果返回给Driver Program。
- Task（任务）：Task是由SparkContext发送到Executor上执行的最小工作单元。
- Cluster Manager（集群管理器）：负责资源分配的服务，可以是YARN、Kubernetes或Spark自己的集群管理器。
- Driver Program（驱动程序）：运行Application main()函数并创建SparkContext的进程，负责提交Job，转化为Task，并协调各Executor间的Task调度。Driver Program可以运行在集群内或集群外。
- Application（应用程序）：用户编写的基于Spark的程序，通过调用Spark API来实现数据处理的应用程序，由一个Driver程序和多个Executor程序组成，以用户定义的main方法作为入口。
- SparkContext：Spark的所有功能的主要入口点，是用户逻辑与Spark集群交互的主要接口。通过SparkContext，用户可以连接到Cluster Manager，申请计算资源，以及将应用程序依赖发送到Executors。

#### 简述Spark的调度过程

- 逻辑计划：DAGSchedule将用户的程序代码转换为逻辑执行计划，即有向无环图（DAG）。在DAG中，节点表示RDD，边表示RDD之间的转换。基于DAG，将程序划分为多个 Stage，对于划分后的每个 Stage 都抽象为一个由多个Task 组成的任务集
  - <img src="https://thdlrt.oss-cn-beijing.aliyuncs.com/image-20231210000029930.png" alt="image-20231210000029930" style="zoom: 50%;" />

- 任务调度：TaskScheduler接收DAGScheduler创建的阶段，负责对每个具体的 Task 进行调度，并将这些阶段中的任务分发给集群管理器。
  - 对于TaskScheduler，Spark 中的任务调度分为两种：FIFO（先进先出）调度和 FAIR（公平调度）调度。

#### 简述Spark的程序执行过程

- 程序提交：用户编写的Spark程序提交到相应的Spark运行框架中
- 创建SparkContext：Spark程序启动时，首先会创建一个SparkContext对象为本次程序的运行环境，这个对象是程序与Spark集群交互的主要接口。
- 集群资源连接：SparkContext会与集群管理器（例如YARN、Mesos或Spark自身的集群管理器）进行通信，以获取执行程序所需的资源。
- 获取Executor节点：一旦资源分配完成，SparkContext会在集群中可用的节点上启动Executor进程。这些进程是执行具体计算任务的实体。
- 代码分发：SparkContext将用户程序中的任务代码和函数序列化后发送到各个Executor。
- 任务执行：最后，SparkContext根据数据的分区和任务的依赖关系，将任务分发到不同的Executor执行。