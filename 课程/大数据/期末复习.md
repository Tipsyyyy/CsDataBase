1. 每章的核心概念，尤其**作业中的问答题**；  
2. 大数据平台（Hadoop，HBase，Hive，Spark等）的**架构和原理**；  
3. MapReduce和Spark的编程模型和编程方法，可以结合讲义、作业和实验中的程序复习；不考MPI编程和HBase编程。其中程序填空要求**填代码**（可以用不同的语言，但要表达清楚），**MapReduce程序设计**可以写伪代码或代码，**Spark编程**要求能读懂程序，掌握常用API和算子。建议同学们复习时阅读讲义中的代码，并回顾下作业和实验中的编程题。
## 大数据概述

### 1 大数据背景简介

- 大数据背景
	- 信息化浪潮：信息处理-信息传输-信息爆炸
	- #重点 ![[概述#1.请简要介绍四种科学研究范式。|科学研究范式]]

- 什么是数据：对现实世界特定方面的一种记录。这些记录可以是数字、文字、图像、声音等**多种形式**。数据可以以多种形式存在：结构化、半结构化、非结构化数据。
- #重点 ![[概述#2.请解释数据、信息、知识的区别和关系。]]
- 什么是大数据：**超大的**、**难以**用现有**常规**的数据库管理技术和工具**处理**的数据集。

- #重点 ![[概述#4.大数据有哪几个特征？（5v）|大数据5v 特征]]

- 大数据类型
	- 按照结构特征划分：
		- 结构化、半结构化、非结构化
	- #重点 ![[概述#3.请简述结构化数据/半结构化数据/非结构化数据的区别。]]
	- 按照获取和处理方式划分：
		- 在线 （实时）
		- 离线
	- 关联特征划分：
		- 无关联，简单关联数据（键值数据）
		- 复杂关联数据（图数据）

- 大数据涉及的关键技术
	- 软件是大数据的引擎
	- 海量数据**存储**技术：**分布式文件系统**
	- **实时**数据处理技术：**流计算引擎**
	- 数据高速**传输**技术：服务器/存储间**高速通信**
	- 搜索技术：文本检索、智能搜索、实时搜索
	- 数据分析技术：自然语言处理、文本情感分析、机器学习、聚类关联、数据模型
#重点
- ![[概述#5.请简述金融数据的特征。]]

### 2 并行计算基础

- 提高计算机硬件性能的主要手段
	- 提高处理器字长
	- 提高集成度
	- 流水线等微体系结构技术（指令级并发）
	- 提高处理器频率
	- 单核处理器性能提升接近极限

- Scale up：**纵向扩展**，指的是通过**增强单个节点的硬件性能**来提高系统的处理能力。
		- 优点：维护简单，无需更改架构
		- 缺点：成本高，物理上限，故障
- Scale out：**横向扩展**，指的是通过**增加更多的节点**到现有系统中，分散处理负载。每个节点可能性能普通，但通过**并行工作**来提升整体性能。
	- 优点：灵活，中低端硬件，容错性
	- 缺点：分布式架构，管理较为复杂

- #重点 ![[课程/大数据/作业/p2#1.简述为什么需要并行计算？|为什么需要并行计算]]

- ![[概述#分类|并行计算的分类]]
- 并行计算的主要技术特点[[概述#问题|问题]]
	- #重点  ![[课程/大数据/作业/p2#3.为什么可靠性设计与容错是并行计算的主要技术问题？]]
- ![[概述#系统性能评估]]

-  MPI 并行程序设计的特点：提供可靠的、**面向消息***（基于消息传递）的通信；在高性能科学计算领域广泛使用，适合于处理计算密集型的科学计算；**独立于语言**的编程规范，可移植性好。**并行计算粒度大**，特别适合于大规模可扩展并行算法
	- 用户必须通过**显式地发送和接收消息**来实现处理机间的**数据交换**。
	- 每个并行进程均有自己独立的地址空间，相互之间访问不能直接进行，必须通过显式的消息传递来实现。（所有节点运行同一个程序，但处理不同的数据）

- MPI 通信机制
	- 点对点通信：同步、异步
	- 节点集合通信：广播、同步、规约（对一组数据进程执行特定操作如求和并传送给一个进程）等
	- 用户自定义的复合数据类型传输

- 不足：
  - 无良好的数据和任务划分支持
  - 缺少分布文件系统支持分布数据存储管理
  - 通信开销大，当计算问题复杂、节点数量很大时，难以处理，性能大幅下降
  - 无节点失效恢复机制，一旦有节点失效，可能导致计算过程无效
  - 缺少良好的构架支撑，程序员需要考虑以上所有细节问题，**程序设计较为复杂**

## Hadoop 与 MapReduce

### 3 MapReduce 简介

- 大数据处理：**分而治之**
	- 前后数据项之间**具有强依赖关系**的计算只能串行（如斐波那契）
	- 当大数据可以划分为具有同样计算过程的数据块，并且**之间不存在数据依赖关系**时使用并行计算
	- ![image.png|350](https://thdlrt.oss-cn-beijing.aliyuncs.com/20240102143141.png)
	- <img src="https://thdlrt.oss-cn-beijing.aliyuncs.com/image-20230924175519140.png" alt="image-20230924175519140" style="zoom:25%;" />

- ![[Hadoop#Map 和 Reduce]]

### 4 Google MapReduce 的基本架构

#### Google MapReduce
- #重点  ![[课程/大数据/作业/p3#1.简述MapReduce的主要功能和设计思想。|MapReduce的主要功能和设计思想]]
- 工作过程
	- ![image.png](https://thdlrt.oss-cn-beijing.aliyuncs.com/20240102152159.png)
	- 首先对输入数据切片（slip）
	- 用户作业将程序提交给主节点，主节点寻找可用的 map、reduce 节点节点并**传送程序给节点**
	- map 节点**启动任务**，将中间结果存储在本地并**告知主节点**
	- 所有 map 节点完成之后启动 Reduce ，从 map 节点告诉主节点的位置取数据
	- reduce 节点将计算结果**汇总到结果文件**

- ![[Hadoop#失效处理]]

- ![[Hadoop#优化]]

#### GFS
- Google GFS 是一个基于**分布式集群**的大型分布式文件系统，为 MapReduce 计算框架提供数据存储和数据可靠性支撑；数据存储在物理上分布的每个节点上，但通过 GFS 将整个数据形成一个**逻辑上整体的文件。**
- ![[Hadoop#基本架构]]
- #重点 ![[课程/大数据/作业/p3#2.简述GFS的基本设计原则和数据访问过程。]]

#### BigTable 基本工作原理
- 在 GFS 之上的一个**结构化数据**存储和访问管理系统
- 主要解决一些大型媒体数据（Web 文档、图片等）的结构化存储问题。其结构化粒度没有那么高，也没有事务处理等能力，因此，它并**不是真正意义上的数据库。**

- 设计目标：高度可扩展、高吞吐、海量服务、高容错、多类型数据

- #重点  ![[课程/大数据/作业/p3#3.简述BigTable的数据模型设计。|p3]]
- ![[Hadoop#BigTable 基本架构]]

### 5 Hadoop MapReduce 基本架构

- Hadoop 是一个能够对大量数据进行**分布式处理的软件框架**，并且是以一种可靠、高效、可伸缩的方式进行处理的，
- 特性：高可靠性；高效性；高可扩展性；高容错性；成本低；运行在 Linux 平台上；支持多种编程语言。

#### HDFS

 - 基本构架
	 - ![image.png|400](https://thdlrt.oss-cn-beijing.aliyuncs.com/20240102164738.png)
	 - #重点  ![[课程/大数据/作业/p4#简述HDFS中NameNode、DataNode的SecondaryNamedNode的作用|p4]]
	 - #重点  ![[课程/大数据/作业/p4#简述HDFS是如何应对NameNode和DataNode出错的|p4]]
 - ![[Hadoop#纠错]]
 - HDFS 客户端：
	 - HDFS 客户端是一个库，**暴露了 HDFS 文件系统接口**
	 - 严格来说，客户端并不算是 HDFS 的一部分。
	 - 客户端可以支持打开、读取、写入等常见的操作，提供 shell 命令以及 Java 接口

- 读写过程
	- ![image.png|375](https://thdlrt.oss-cn-beijing.aliyuncs.com/20240102172950.png)
	- ![image.png|400](https://thdlrt.oss-cn-beijing.aliyuncs.com/20240102173023.png)
		- ack package：确认收到

#### Hadoop MapReduce

- 基本构架 (1.0)
	- ![image.png|425](https://thdlrt.oss-cn-beijing.aliyuncs.com/20240102174417.png)
	- ![image.png|425](https://thdlrt.oss-cn-beijing.aliyuncs.com/20240102174808.png)
	- 所有任务由 JobTracker 调度分配，存在**单点故障**问题
	- TaskTracker **资源分配不够合理**（只根据任务个数进行分配），不能按需分配


- YARN (v2.0)
	- ![image.png|425](https://thdlrt.oss-cn-beijing.aliyuncs.com/20240102174621.png)
	- ![image.png|425](https://thdlrt.oss-cn-beijing.aliyuncs.com/20240102180223.png)********
- ![image.png](https://thdlrt.oss-cn-beijing.aliyuncs.com/20240102175152.png)
	- #重点  ![[课程/大数据/作业/p4#简述YARN的设计|p4]]
### 6/7/8/9 MapReduce 编程


![[Hadoop#MapReduce 流水线]]
#### MapReduce 编程编程

- ![[Hadoop#基本框架]]

- 用户自定义数据类型
	- 实现 Writable 接口（或 WritableComparable）
	- 含 write、readFields
- 复合键值对的使用：使用复合键值对进行分布式排序（避免进行本地排序）
	- ![[Hadoop#复合键值对]]

- ![[Hadoop#自定义输入输出类型]]

- ![[Hadoop#自定义Partitioner和Combiner]]

- ![[Hadoop#迭代MapReduce]]

- ![[Hadoop#链式MapReduce任务]]
#重点 
- ![[Hadoop#全局数据传递]]

- [[Hadoop#案例应用]]

- [[课程/大数据/实验/p2|实验二]]

### \*10/11/12 MapReduce 数据挖掘基础算法（不考实现）

- [[Hadoop#MapReduce数据挖掘基础算法]]

### 13 NoSQL 数据库

- RDBMS：关系型数据库管理系统
	- 模式固定，面型行的数据库，具有 ACID 性质和复杂的 SQL 查询
	- 效率低、复杂、扩展性差
- SQL：结构化查询语言，用于管理关系数据库管理系统（RDBMS）

- 关系型数据库
  - 优势：以完善的**关系代数**理论作为基础，有严格的标准，支持事务**ACID**四性，借助索引机制可以实现**高效的查询**
  - 劣势：**可扩展性较差**，无法较好支持海量数据存储，数据模型过于**死板**、**无法较好支持 Web 2.0 应用**，事务机制影响了系统的整体性能等

- NoSQL 数据库
  - 优势：可以支持**超大规模**数据存储，灵活的数据模型可以很好地支持 Web 2.0 应用，具有强大的**横向扩展能力**等
  - 劣势：缺乏数学理论基础，复杂查询性能不高，大都不能实现事务强一致性，很难实现数据完整性

#重点 
- ![[课程/大数据/作业/p6#1.简述RDBMS和NoSQL数据库的区别|p6]]
#### NoSQL

- Not Only SQL：不仅仅是 SQL，泛指非关系型数据库
- 放松了对传统数据库**ACID 事务处理特征和数据高度结构化的要求**，以简化设计、提高数据存储管理的**灵活性**、提高处理性能、支持**良好的水平扩展**。

- ![[NoSQL#NoSQL兴起原因]]

- ![[NoSQL#NoSQL分类]]

- NoSQL 的**三大基石**
	- CAP
	- BASE
	- 最终一致性
#重点 
- ![[课程/大数据/作业/p6#2.简述CAP定理的含义|p6]]

#重点 
- ![[课程/大数据/作业/p6#3.简述ACID和BASE的区别|p6]]
- ![[NoSQL#最终一致性]]
- ![[NoSQL#NewSQL]]
### 14 HBase 基础原理与程序设计

- 为什么需要 HBase
	- Hadoop 无法满足大数据实时访问（HDFS 面向面向批量访问而不是随机访问）
	- 传统关系型数据库扩展性差，结构化浪费空间
	- 解决**大规模数据实时处理**问题

- 与 MapReduce 协同工作，为 MapReduce **提供数据输入输出**，以完成数据的并行化处理 
![[HBase#^c0574a]]
 
#### HBase 数据模型
#重点 
- ![[课程/大数据/作业/p7#简述HBase的数据模型|p7]]
#重点 
- ![[课程/大数据/作业/p7#简述HBase的概念视图和物理视图的不同|p7]]
- ![image.png|400](https://thdlrt.oss-cn-beijing.aliyuncs.com/20240103193327.png)
- 

#### HBase 的基本架构

#重点 
- ![[课程/大数据/作业/p7#简述HBase系统基本架构以及每个部分的作用|p7]]
##### 数据存储结构

- ![image.png|450](https://thdlrt.oss-cn-beijing.aliyuncs.com/20240103201936.png)
	- 一个大表分隔为许多 Region 进行存储
	 
- <img src="https://thdlrt.oss-cn-beijing.aliyuncs.com/image-20231123225704179.png" alt="image-20231123225704179" style="zoom:50%;" />
  - Region Server cluster->Region server->Region->memStore+StoreFile
  - **Region**：表的一个子集，包含了一系列连续的行，数据**物理存储和分布的基本单元**。
    - 由一个 RegionServer 负责管理数据的读写，当大小增大到一定阈值会被**分裂**，新的 Region**最初**并不复制或移动数据。它们仍然读取原始 Region 的存储文件（由于不需要立即复制数据，这使得拆分操作可以**非常快速**地完成，几乎是瞬间的）。（异步）随后在后台进行合并过程，逐渐把原始文件中属于新 Region 的数据**异步地写入新的独立文件**。
    - **即时可用**：由于新 Region**一开始就可以读取**原始 Region 的文件，它们立即变得可用。
    - **最终一致性**：随着时间的推移，新 Region**最终**会有自己独立的存储文件，完成分裂。
- **store**：
  - Store 是 Region 中的**逻辑分区**，对应于一个列族，**每个列族存储在自己**的 Store 中。
- **memstore**：
  - MemStore 是 Store 的一部分，是一个位于**内存**中的数据结构，用来**缓存**即将写入文件系统的数据。
- **storefile**：
  - StoreFile 是 Store 的**持久化表示**，是存储在**HDFS 上的文件**，具体格式为 HFile。

##### 数据查询和定位
#重点 
- ![[课程/大数据/作业/p7#简述HBase数据查询定位方法及三层结构中各层次的名称和作用|p7]]
![[HBase#HBase 数据工作原理]]

#### HBase Shell

![[HBase#HBase表设计]]

![[HBase#HBase Shell]]
#重点 
- [[课程/大数据/实验/p3#Shell编程|实验p3]]

### 15 Hive 简介
- Hive 包括一个高层语言的执行引擎，类似于**SQL**的执行引擎，方便对数据进行查询汇总、分析
	- 自动将 SQL 转化为 MapReduce 执行

- 优点：可扩展性、延展性、良好的容错性
- 缺点：
	- 查询延时很严重，不适用于交互查询系统
	- 不是为在线事务处理设计，主要用于 OLAP 而不是而不是 OLTP
		- OLTP 是一种面向**事务**的数据处理方式。它主要用于管理日常事务和操作，如银行交易、零售销售等。（高实时性）
	    - OLAP 是一种面向**分析**的数据处理方式。它主要用于复杂的数据分析和查询，包括趋势分析、报告生成等。

- Hive **本身不存储数据，是逻辑表**：通过**元数据来**描述 Hdfs 上的结构化文本数据。

- **逻辑上**，数据是存储在 Hive 表里面的，而表的元数据描述了数据的布局。我们可以对表执行过滤，关联，合并等操作。在 Hadoop 里面，**物理数据一般是存储在 HDFS 的，而元数据是存储在关系型数据库的。**

-  RDBMS vs. Hive
	- HiveQL 提供提供了与 SQL 类似的查询语言
	- Hive 使用的是 Hadoop 的 HDFS，关系数据库则是服务器本地的文件系统；
	- Hive 使用的计算模型是 MapReduce，而关系数据库则是自己设计的计算模型；
	- 关系数据库都是为**实时查询**的业务进行设计的，而 Hive 则是为**海量数据**做数据挖掘设计的，**实时性**很差

#重点 
![[课程/大数据/作业/p8#简述Hive和HBase的区别|p8]]

#重点 
![[课程/大数据/作业/p8#简述Hive的体系结构和各组成模块的作用|p8]]

#重点 
![[课程/大数据/作业/p8#简述Hive的数据模型|p8]]

![[Hive#Hive QL]]

#重点 
- [[课程/大数据/作业/p8#编写HiveQL语句完成实验3中三张表的创建、加载数据，查询BigData成绩为90及以上的学生姓名，并按成绩从大到小排序。|p8]]

### 16 Spark 简介

- MapReduce 计算模式的缺陷：2阶段固定模式，磁盘计算**大量 I/O 性能低下**
- Spark**基于内存计算**思想提高计算性能，提出一种基于内存的弹性分布式数据集(RDD)，通过对 RDD 的一系列操作完成计算任务，可以大大提高性能

- RDDs
  - 基于 RDD 之间的**依赖关系组成 lineage**，通过重计算以及 checkpoint 等机制来保证整个分布式计算的容错性。
  - 只读、可分区，这个数据集的**全部或部分可以缓存在内存中**，在多次计算间重用，弹性是指内**存不够时可以与磁盘进行交换**。

- spark 与 hadoop
	- spark 中间数据中间数据在内存中，不需要反复 IO，处理效率高
	- spark 引入 RDD 抽象以及检查点，容错性更高
	- spark 支持支持更多种类的操作，更加通用

#重点 
![[p9#简述Spark的技术特点]]
#### Spark 架构

#重点 
![[p9#简述Spark的基本构架组成]]
****
#重点 
![[p9#简述 Spark 的调度过程]]

#重点 
![[Spark#Spark的程序执行过程]]

### 17/18/19/20 Spark 编程

- 

![[Spark#示例]] 

#### 高级编程

##### Spark SQL

- 

#重点 

![[p10#简述RDD、DataFrame、DataSet的区别]]

##### Spark 机器学习

- MLlib 是 Spark 实现一些**常见的机器学习算法和实用程序**，面向 RDD；

- Spark ML 是基于 DataFrame 进行机器学习 API 的开发，**抽象层次更高**。把数据处理的流水线抽象出

#重点 
- ![[p10#简述Spark ML的流水线含义]]

##### Spark 流式计算

#重点 
![[p10#简述批量计算和流式计算的区别]]

#重点 
![[p10#简述Spark Streaming和Spark Structured Streaming的区别]]

##### GraphX
- GraphX是Spark中用于**图和图并行计算的API**。

#重点 
![[p10#简述GraphX的弹性分布式属性图的设计思想]]

#重点 
[[课程/大数据/实验/p4|p4]]

### 21 云计算简介

![[云计算]]
