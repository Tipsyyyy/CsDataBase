{"path":"课程/大数据/课件/02 Parallel Computing.pdf","text":"并行计算技术简介 摘要 ¨ 为什么需要并行计算？ ¨ 并行计算技术的分类 ¨ 并行计算的主要技术问题 ¨ M PI 并行程序设计 ¨ 为什么需要大规模数据并行处理？ 摘要 ¨ 为什么需要并行计算？ ¨ 并行计算技术的分类 ¨ 并行计算的主要技术问题 ¨ M PI 并行程序设计 ¨ 为什么需要大规模数据并行处理？ 为什么需要并行计算 ¨ 贯穿整个计算机技术发展的核心目标： 提高计算性能！ ¤ I n t el C PU 发展： n 1993 P en t i u m 主频 60M H z ， 6 0 M f l op s n 2011 i7 - 2600k 主频 2. 93G H z ， 1 8 7 G f l op s n 2016 i7 - 6900k 主频 4G H z ， 1 0 2 3 G f l op s n 2018 i9 - 9900k 主频 5G H z ， 8 核 16 线程 n 2020 i9 - 10900k 主频 5. 3G H z ， 10 核 20 线程 ¤ 通过芯片制程工艺 + 处理器微架构设计 + 服务器平台技术，使 C PU 性能 大幅提升 4 为什么需要并行计算 ¨ 超级计算机（ 2023 年 6 月） 5 N o . 7 S u n w a y Ta i h u l i g h t （中国） 处理器： 10, 649, 600 个 峰值速度： 93. 01P F l op/ s 神威 “太湖之光”超级计算机全部 使用中国自主知识产权的芯片。 处理器 ： 7, 630, 848 个 峰值速度： 442. 01 PF l o p /s F u g a ku 超算原来被称为“ P o st K ” ， 是曾经的世界第一 K co m p u t e r 产品 的第四代，采用 AR M 架构 的富士通 A6 4 F X 处理器。 No . 2 F u g a ku （日本） 处理器： 8, 699, 904 个 峰值速度： 11 9 4 PF l o p /s Fr o n t i e r 是美国能源部橡树岭国家实 验室（ OR N L ） 推出的新超级计算 机，成为全球第一款 E 级超算（百 亿亿次），峰值运行达到第二名的 三倍多。 No . 1 F r o n t ie r （美国） 引自： h t t p s: / / w w w . ch i n a st o r . co m / h p c - to p 5 0 0 / 为什么需要并行计算 ¨ T es l a AI Da y ： D1 芯片与 D oJ o 超级计算机 ¤ 实现人工智能训练的超高算力，同时还要扩展带宽、减少延迟、节省 成本 6 25 个 D1 芯片组成一个 Tr a i n i n g Ti l e ；然后 12 个训练片可以组成一个服 务器机柜，共 108 PFl o p s ；几个机柜再组成 Do jo 超级计算机。 提高计算机性能的主要手段 ¨ 提高处理器字长 ： 71 年， 4004 ， 4bits ； 78 年， 8086 ， 8bits ； 82 年， 80286 ， 16bits ； 85 年 ~90s 80386 ， 486 ， P en t i u m P2 /P3 /P4 ： 32bits 05 年 ~ 现在， P en t i u m D 往后 - C or e i 3 /i 5 /i 7 /i 9 ： 64bits 7 提高计算机性能的主要手段 ¨ 提高集成度 ¤ 摩尔定律 ：芯片集成度每 18 个月翻一倍，计算性能提高一倍（ 1965 年， 戈登 · 摩尔） 8 挑战 1 ： 发热 挑战 2: 移动化 提高计算机性能的主要手段 ¨ 流水线等微体系结构技术 ¤ 实现指令级并行（ I n s t r u c t i on - L ev el P a r a l l el i s m , IL P ） RI SC 结构 5 级流水线：分支预测，寄存器重命名，超长指令字（ VLI W ）， 超标量 ( Su p er s c a l a r ) ，乱序执行， C a c h e…… 9 提高计算机性能的主要手段 ¨ 提高处理器频率 10 单核处理器性能提升接近极限 ¨ 1.V L S I 集成度不可能无限制提高 ¤ 芯片集成度已进入极小尺度级别，集成度不可能无限制提高 11 1n m( 纳米 ) 约头发直径的 6 万分之一 或 4 个原子长度 10 - 20n m 仅有几百个原子 的长度 单核处理器性能提升接近极限 ¨ 2. 处理器的指令级并行度提升接近极限 12 长指令字，流水线，分支预测，寄存器命名，超标量，乱序执行，动态 发射，高速缓冲（ Cac h e ） …… 高级流水线等各种复杂的微体系结构技术都已得到研究应用，难以进一 步挖掘更多的指令级并行性（ IL P ） 单核处理器性能提升接近极限 ¨ 3. 处理器速度和存储器速度差异越来越大 ¤ 处理器性能每 2 年翻一倍，而存储器性能每 6 年翻一倍 ¤ 为了匹配两者间速度差异，处理器需要做越来越大的 Ca c he 13 CP U 计算速度： ~1ns 级别 主存访问速度： 100ns 级别 单核处理器性能提升接近极限 ¨ 4. 功耗和散热大幅增加超过芯片承受能力 ¤ 晶体管密度不断提高，单位面积功耗和散热大幅增加。主频提高导致 功耗和散热急剧增加 ¤ 功耗 P= C V 2 f ， C ：时钟跳变时门电路电容， V ：电压， f ：主频 ¤ 晶体管数越多，电容越大 => 功耗越大；主频越高 => 功耗越大 14 Ci t e f r o m E dw a r d L . B o s w o r t h , Th e P o w e r W a l l , 2 0 1 0 单核处理器性能提升接近极限 ¨ 2005 年前，人们预期可以一直提升处理器主频 ¨ 但 2004 年 5 月 I n t el 处理器 T ej a s a n d J a yh a w k (4GHz) 因无法解决散热问题最终 放弃，标志着升频技术时代的终结 15 Ci t e f r o m E dw a r d L . B o s w o r t h , T h e P o w e r W a l l , 2 0 1 0 向多核并行计算发展成为必然趋势 ¨ 多核 / 众核并行计算 ¤ 2005 年 I n t el 全面转入多核计算技术，采用多核 / 众核构架，简化单处理器的复杂设计，代之 以单个芯片上设计多个简化的处理器核，以多核 / 众核并行计算提升计算性能 16 典型的双核处理器结构 • 双核 : P en t i u m D, EE, X eon C or e 2 Du o E 系 列 , T 系列 , C o re i3 , i5 • 4 核 : C or e 2 Qua d Q C or e i5 , i7 • 6 核 : C or e i 7 9 7 0 /9 8 0 / … • 8 核 : A M D Bu l l d oz er • 10 核： C or e i9 - 7900X ¨ 多核 / 众核并行计算 I n t el 实验芯片 Si n g l e C l ou d C h i p , SC C ： 48 核 T er a f l op s ， 80 核 17 Ø A SC I R ed ： 1996 ，第一个达到 1 T F l op s ( 1 0 万亿次浮点运算 ) 的并行计算系 统，使用了 10,000 颗 P en t i u m Pr o 处理器 (200MHz) ，耗电 500k W ，外加 500k W 用于机房散热 Ø T er a f l op s ： 达到 1 . 0 1 T F l op s ( 3 . 1 6 G H z ) 1 . 8 1 T F l op s ( 5 . 7 G H z ) ， 功耗 62W ！ Ci t e f r om I n t el w eb s i t e: http : / / te c hr e s e a r c h. i nte l . c o m / p r o j e c td e ta i l s . a s p x ? i d = 1 5 1 向多核并行计算发展成为必然趋势 ¨ 多核 / 众核并行计算 ¤ 根据摩尔定律， I n t el 预计其通用的众核并行计算芯片 ¤ 2015 年： 128 核 ¤ 2017 年： 256 核 ¤ 2019 年： 512 核 ¤ 2023 年： 2048 核 NV I D I A GP U G r a p h i c Pr oc es s i n g U n i t ，主要用于图形图像并行处理 T es l a M 2 0 5 0 /2 0 7 0 : 4 4 8 核 S2 0 5 0 1 U G PU 处理系统 : 4 个 M 2 0 5 0 /2 0 7 0 ， 1792 核 18 向多核并行计算发展成为必然趋势 ¨ 多核 / 众核并行计算 ¤ AI 时代又进一步催生了 T PU 、 N PU 等众核 AI 处理器的诞生 n 黄仁勋提出的 Hu a n g ‘ s L a w —— GP U 将推动 AI 性能实现逐年翻倍 19 向多核并行计算发展成为必然趋势应用领域计算规模和复杂度大幅提高 ¨ 爆炸性增长的 We b 规模数据量 ¤ G oog l e 从 2004 年每天处理 100T B 数据到 2008 年每天处理 2 0 PB ¤ 2009 年 eBa ys 数据仓库，一个有 2 PB 用户数据，另一个 6 . 5 PB 用户数据包含 170T B 记录且每天 增长 150GB 个记录； F a c e b ook ： 2 . 5 PB 用户数据，每天增加 15T B ¤ 世界最大电子对撞机每年产生 1 5 PB( 1 千 5 百万 G B) 数据 ¤ 2015 年落成的世界最大观天望远镜主镜头像素为 3. 2G ，每年将产生 6 PB 天文图像数据； ¤ 欧洲生物信息研究中心 ( E BI ) 基因序列数据库容量已达 5 PB ；中国深圳华大基因研究所成为全 世界最大测序中心，每天产生 300GB 基因序列数据（每年 100T B ） 20 应用领域计算规模和复杂度大幅提高 ¨ 超大的计算量 / 计算复杂度 ¤ 用 SG I 工作站进行电影 渲染时 ， 每帧 一般需要 1 ～ 2 小时 ¤ 一部 2 小时的电影渲染需要： 2 小时 x3 6 0 0 秒 x2 4 帧 x( 1 ~ 2 小时 ) /2 4 小时 =2 0 ~ 4 0 年 ! ¤ 特殊场景 每帧 可能 需要 60 个小时 （ 影片《星舰骑兵》中数千只蜘蛛爬行的场面 ），用 横向 4096 象素分辨率进行渲染时，如果 以 每帧 60 个小时 的速度 ，则 1 秒的放映量 （ 24 帧 ） 需要 60 天的渲染时间 ， 1 分钟则需要 10 年 ！ ¤ 世界著名的数字工作室 D i g i t a l D om a i n 公司用了一年半的时间，使用了 300 多台 SG I 超级工作 站， 50 多个特技师一天 24 小时轮流制作 《 泰坦尼克号 》 中的电脑特技 21 解决方案 —— 并行计算！ 22 Cl u s t e r 并行计算技术的发展趋势和影响 ¤ 越来越多的研究和应用领域需要使用并行计算技术 n 并行计算技术将渗透到每个计算应用领域，尤其是涉及到大规模数据和复杂计 算的应用领域 ¤ 并行计算技术将对传统计算技术产生革命性的影响 n 并行计算技术将影响传统计算技术的各个层面，与传统计算技术相互结合产 生很多新的研究热点和课题 n 很多传统的串行算法和计算方法都将需要重新研究和设计其并行化算法和计 算方法 23 为什么需要学习并行计算技术？ ¨ 软件开发 / 程序设计人员面临挑战！ ¤ 20 - 30 年里程序设计技术的最大的革命是面向对象技术 ¤ 下一个程序设计技术的革命将是并行程序设计 ¤ 今天绝大多数程序员不懂并行设计技术，就像 15 年前绝大多数程序员 不懂面向对象技术一样 24 Ci t e f r om H er b S u t t er , T h e F r ee L u n c h I s O v er - A F u n d a m e n t a l Tu r n To w a r d C o n c u r r e n c y i n So f t w a r e ， Dr . Do bb' s J o u r n al , 3 0 ( 3 ) , Ma r c h 2 0 0 5 摘要 ¨ 为什么需要并行计算？ ¨ 并行计算技术的分类 ¨ 并行计算的主要技术问题 ¨ M PI 并行程序设计 ¨ 为什么需要大规模数据并行处理？ 并行计算技术的分类 ¨ 按数据和指令处理结构：弗林 ( F l yn n ) 分类 ¨ 按并行类型 ¨ 按存储访问构架 ¨ 按系统类型 ¨ 按计算特征 ¨ 按并行程序设计模型 / 方法 26 弗林分类 ¤ SI SD ：单指令单数据流 传统的单处理器串行处理 ¤ SI M D ：单指令多数据流 向量机，信号处理系统 ¤ M I SD ：多指令单数据流 很少使用 ¤ MI MD ：多指令多数据流 最常用， T O P5 0 0 基本都属于 MI MD 类型 27 弗林分类 28 SI SD SI M D MI MD Ci t e f r o m J i mmy L i n , W h a t i s c l o u d c o mpu t i n g , 2008 按并行类型分类 n 位级并行（ Bi t - L ev el P a r a l l el i s m ） n 指令级并行（ IL P ： I n s t r u c t i on - L ev el P a r a l l el i s m ） n 线程级并行（ T h r ea d - L ev el P a r a l l el i s m ） n 数据级并行 ：一个大的数据块划分为小块，分别由不同的处理器 / 线程处理 n 任务级并行 ：一个大的计算任务划分为子任务，分别由不同的处理器 / 线程 来处理 29 按存储访问结构分类 ¨ 共享内存（ Sh a r ed M em or y) – UMA 结构 ( U n i f or m M em or y A c c es s ) ¤ 所有处理器通过总线共享内存 ¤ 多核处理器， SM P…… ¨ 分布共享存储体系结构 – NU MA 结构 ( N on - U n i f or m M em or y A c c es s ) ¤ 各个处理器有本地存储器 ¤ 同时再共享一个全局的存储器 ¨ 分布式内存 – NU MA 结构 ¤ 各个处理器使用本地独立的存储器 30 … … … … M M M … … M M M 按系统类型分类 n 多核 / 众核并行计算系统 MC （ Multi - C or e ） n 或 Ch i p - l ev el m u l t i p r oc es s i n g , C M P n 对称多处理系统 SM P （ Sym m et r i c M u l t i Pr oc es s i n g ） n 多个相同类型处理器通过总线连接并共享存储器 n 大规模并行处理 M PP （ M a s s i v el y P a r a l l el Pr oc es s i n g ） n 专用内联网连接一组处理器形成的一个计算系统 n 集群 C l u s t er n 网络连接的一组商品计算机构成的计算系统 n 网格 Gr id n 用网络连接远距离分布的一组异构计算机构成的计算系统 n 云 C l ou d n 通过互联网按需访问计算资源 31 按系统类型分类 n 不同系统的特征和对比 n 从 MC 到 C l ou d ， 耦合度越来越低，但可扩展性越来越高，系统规模越来越大， 而能耗也越来越高 n MC 处理器核通过 NOC ( 片上网络 ) 集成在一个芯片上，通常使用混合式内存 访问机制 ( 本地缓存加全局内存 ) ，功耗很低 n SM P 使用独立的处理器和共享内存，以总线结构互联，运行一个操作系统 , 定制成本高 , 难以扩充 , 规模较小 (2 - 8 处理器） n M PP 使用独立的处理器及独立的内存、 OS ，专用的高速内联网络，难以升 级和扩充，规模中等 32 按系统类型分类 n 不同系统的特征和对比 n 从 MC 到 C l ou d ， 耦合度越来越低，但可扩展性越来越高，系统规模越来越大， 而能耗也越来越高 n C l u s t er 使用商品化的刀片或机架服务器，以网络互联为一个物理上紧密的 计算系统，可扩展性强，规模可小可大，是目前高性能并行计算最常用的 形式 n Gr id 则为地理上广泛分布的异构计算资源构成的一个极为松散的计算系统， 主要用于并行度很低的大规模科学计算任务 n C l ou d 云计算就是通过互联网按需访问计算资源，即应用程序、服务器 （物理服务器和虚拟服务器）、数据存储 、开发工具、网络功能等，这 些资源托管在由云服务提供商管理的远程数据中心上。 33 按计算特征分类 n 数据密集型并行计算 (Data - I n t en s i v e P a r a l l el C om p u t i n g ) n 数据量极大、但计算相对简单的并行处理，如大规模 We b 信息搜索 n 计算密集型并行计算 ( C om p u t a t i on - I n t en s i v e P a r a l l el C om p u t i n g ) n 数据量相对不是很大、但计算较为复杂的并行处理，如： 3 - D 建模与渲染， 气象预报，科学计算 …… n 数据密集与计算密集混合型并行计算 n 兼具数据密集型和计算密集型特征的并行计算，如 3D 电影渲染 34 按并行程序设计模型 / 方法分类 n 共享内存变量 ( Sh a r ed M em or y V a r i a b l es ) n 多线程共享存储器变量方式进行并行程序设计，会引起数据不一致性，导致数据和资源访问冲突， 需要引入同步控制机制； Pt h r ea d ， O p en M P ：共享内存式多处理并行编程接口 n 消息传递方式 ( M es s a g e P a s s i n g ) n 对于分布式内存结构，为了分发数据和收集计算结果，需要在各个计算节点间进行数据通信，最常 用的是消息。 n 传递方式； M PI ：消息传递并行编程接口标准 n M a p R ed u c e 方式 n G oog l e 公司提出的 M a p R ed u c e 并行程序设计模型，是当时最易于使用的并行程序设计方法，广泛使用 于搜索引擎等大规模数据并行处理 35 发展历史和现状 ¨ 1975 - 1985 ¤ 主要是向量机技术，如 C r a y1 ， C r a y2 。但基于多线程的并行计算也逐步引 入。 ¨ 1986 - 1995 ¤ 大规模并行处理 M PP 成为主流并行计算技术，消息传递编程接口 M PI 得到开 发应用。目前 T O P5 0 0 中有 84 个基于 M PP 。 ¨ 1995 - 现在 ¤ C l u s t er 和 Gr id 并行计算技术成为主流，但目前 Gr id 的发展已呈下降趋势，目 前 T O P5 0 0 中有 414 个基于 C l u s t er 。 36 发展趋势 ¨ SM P 作为共享内存式小规模并行计算技术一直活跃 ¤ 60 - 70 年代基于大型机的 SM P 系统， 80 年代基于 8 0 3 8 6 /8 0 4 8 6 的 SM P 系统， 90 年代到目前基于多核的个人电脑、服务器大都基于 SM P ¨ 多核 / 众核并行计算成为重要发展趋势 ¤ 由于单核处理器性能发展的瓶颈，同时由于多核 / 众核计算计算自身具有的 体积小、功耗低等诸多技术特点和优势，今后多核 / 众核并行计算会称为必 然趋势 ¨ 并行计算软件技术远远落后于硬件发展速度 ¤ 并行计算硬件技术水平和规模发展迅速，但并行计算软件技术远远跟不上 硬件发展水平和速度，缺少有效的并行计算软件框架、编程模型和方法 37 摘要 ¨ 为什么需要并行计算？ ¨ 并行计算技术的分类 ¨ 并行计算的主要技术问题 ¨ M PI 并行程序设计 ¨ 为什么需要大规模数据并行处理？ 并行计算的主要技术问题 39 数据怎么存？怎么算？ 并行计算的主要技术问题 n 多核 / 多处理器网络互连 结构 技术 n 存储 访问 体系结构 n 分布式 数据与文件管理 n 并行计算任务分解与算法设计 n 并行程序设计模型和方法 n 数据同步访问和通信控制 n 可靠性设计与容错技术 n 并行计算软件框架平台 n 系统性能评价和 程序并行度 评估 40 多核 / 多处理器网络互联结构技术 ¨ 主要研究处理器间互联拓扑结构，尤其在包含大量处理器的并行计 算系统中，需要具有良好的互联结构，以保证大量处理器能真正有 效地协同工作，获得应有的并行计算效率。 ¤ 共享总线连接 （ Sh a r ed Bu s ） ¤ 交叉开关矩阵（ C r os s b a r Sw i t c h ） ¤ 环形结构（ T or u s ） ¤ M es h 网络结构（ M es h N et w or k ） ¤ 片上网络（ NOC ， N et w or k - on - ch i p ） ¤ …… 41 存储访问体系结构 ¨ 主要研究不同的存储结构，以及在不同存储结构下的特定技术问 题 ¤ 共享存储器体系结构 ( Sh a r ed M em or y) n 共享数据访问与同步控制 ¤ 分布存储体系结构 ( D i s t r i b u t ed M em or y) n 数据通信控制和节点计算同步控制 ¤ 分布共享存储结构 ( D i s t r i b u t ed Sh a r ed M em or y) n Cac h e 的一致性 问题 n 数据访问 / 通信的时间延迟 42 分布式数据与文件管理 ¨ 并行计算的一个重要问题是，在大规模集群环境下，如何解决大数 据块的划分、存储和访问管理；尤其是数据密集型并行计算时，理 想的情况是提供分布式数据与文件管理系统，如： ¤ R ed H a t G F S ( G l ob a l F i l e Sys t em ) ¤ I BM G PF S ¤ Su n Lu st re ¤ G oog l e G F S( G oog l e F i l e Sys t em ) ¤ H a d oop H D F S( H a d oop D i s t r i b u t ed F i l e Sys t em ) 43 并行计算任务的分解与算法设计 ¨ 一个大型计算任务如何从数据上或者是计算方法上进行适当的划分， 分解为一组子任务以便分配给各个节点进行并行处理，如何搜集各 节点计算的局部结果。 ¤ 数据划分 n 如何将特大的数据进行划分并分配给各节点进行处理 ¤ 算法分解与设计 n 一个大的尤其是计算密集型的计算任务，首先需要寻找并确定其可并行计算的部分，然 后进一步寻找好的分解算法：可把一个整体的算法纵向分解为一组并行的子任务，或者 对于复杂的计算任务可横向分解为多次并行处理过程。 44 并行程序设计模型和方法 ¨ 根据不同的硬件构架，不同的并行计算系统可能需要不同的并行 程序设计模型、方法、语言和编译技术。 ¨ 并行程序设计模型和方法 ¤ 共享内存式并行程序设计 ：为共享内存结构并行计算系统提供的程序 设计方法 , 需提供数据访问同步控制机制 ( 如互斥信号 , 锁等） ¤ 消息传递式并行程序设计 ：为分布内存结构并行计算系统提供的、以 消息传递方式完成节点间数据通信的程序设计方法 ¤ M a p R ed u c e 并行程序设计 ： 为解决前两者在并行程序设计上的缺陷， 提供一个综合的编程框架，为程序员提供了一种简便易用的并行程序 设计方法 45 并行程序设计模型和方法 ¨ 并行程序设计语言 ¤ 语言级扩充 ：使用宏指令在普通的程序设计语言（如 C 语 言）上增加一些并行计算宏指令，如 O p en M P （提供 C ， C++ ， F or t r a n 语言扩充， Li n u x & Wi n d o w s ） ¤ 并行计算库函数与编程接口： 使用函数库提供并行计算编 程接口，如 M PI ( 消息传递接口 ) ， C U D A ( N V I D I A G PU ) ¨ 并行编译与优化技术 ¤ 编译程序需要考虑编译时的自动化并行性处理，以及为提 高计算性能进行并行计算优化处理 46 int main(int argc, char *argv[]) { const int N = 100000; int i, a[N]; #pragma omp parallel for for (i = 0; i < N; i++) a[i] = 2 * i; return 0; } 数据同步访问和通信控制 n 如何解决并行化计算中共享数据访问和节点数据通信问题 n 共享数据访问和同步控制 n 在包含共享存储器结构的系统中，不同处理器 / 线程访问共享存储区时，可 能会导致数据访问的不确定性（竞争状态， r a c e c on d i t i on ），因此需要考虑 使用同步机制（互斥信号，条件变量等）保证共享数据和资源访问的正确性， 还要解决同步可能引起的死锁问题。 n 分布存储结构下的数据通信和同步控制 n 在包含分布存储器结构的系统中，不同处理器 / 线程需要划分和获取计算数 据，这些数据通常需要由主节点传送到各个从节点；由于各个节点计算速度 不同，为了保证计算的同步，还需要考虑各节点并行计算的同步控制（如 Ba r r i er ，同步障） 47 可靠性设计与容错技术 ¨ 大型并行计算系统使用大量计算机 , 因此 , 节点出错或失效是常态， 不能因为一个节点失效导致数据丢失、程序终止或系统崩溃，因 此，系统需要具有良好的可靠性设计和有效的失效检测和恢复技 术。 ¤ 数据失效恢复： 大量的数据存储在很多磁盘中，当出现磁盘出错和数 据损坏时，需要有良好的数据备份和数据失效恢复机制，保证数据不 丢失以及数据的正确性。 ¤ 系统和任务失效恢复： 一个节点失效不能导致系统崩溃，而且要能保 证程序的正常运行，因此，需要有很好的失效检测和隔离技术，并进 行计算任务的重新调度以保证计算任务正常进行。 48 并行计算软件框架平台 ¨ 提供自动化并行处理能力 ¤ 现有的 O p en M P 、 M PI 、 CUD A 等并行程序设计方法需要程序员考虑和处理数据存储管理、数 据和任务划分和调度执行、数据同步和通信、结果收集、出错恢复处理等几乎所有技术细 节，非常繁琐 ¤ 需要研究一种具有自动化并行处理能力的并行计算软件框架和平台，提供自动化的并行处 理，能屏蔽并行化处理的诸多系统底层细节，交由软件框架来处理，提供必要的编程接口， 简化程序员的编程，让程序员从系统底层细节中解放出来，专注于应用问题本身的计算和 算法的实现。如 G oog l e 和 H a d oop M a p R ed u c e ¨ 高可扩展性和系统性能提升 ¤ 并行计算框架允许方便地增加节点扩充系统，但系统节点的增加不影响程序的编写，并且 要能保证节点增加后系统性能有线性的提升 49 系统性能评估和程序并行度评估 ¨ 系统性能评估 ¤ 用标准性能评估 ( Ben c h m a r k ) 方法评估一个并行计算系统的浮点计算能 力。 Hig h - P er f or m a n c e Li np a c k Ben c h m a r k 是最为知名的评估工具， T O P5 0 0 用其进行评估和排名 ¨ 程序并行度评估 ¤ 程序能得到多大并行加速依赖于该程序有多少可并行计算的比例。经 典的程序并行加速评估公式 Am d a h l 定律 ： 50 S= 其中， S 是加速比， P 是程序 可并行比例， N 是处理器数目 系统性能评估和程序并行度评估 51 根据 Am dah l 定律： 一个并行程序可 加速程度是有限 制的，并非可无 限加速，并非处 理器越多越好 并行比例 vs 加速比 50%=> 最大 2 倍 75%=> 最大 4 倍 90%=> 最大 10 倍 95%=> 最大 20 倍 Ci t e f r om h t t p : / / en . w i k i p ed i a . or g / w i k i / A m d a h l % 2 7 s _ l a w 摘要 ¨ 为什么需要并行计算？ ¨ 并行计算技术的分类 ¨ 并行计算的主要技术问题 ¨ MP I 并行程序设计 ¨ 为什么需要大规模数据并行处理？ M PI 并行程序设计 n M PI ( M es s a g e P a s s i n g I n t er f a c e) ，基于消息传递的高性能并行计算编程接口 n 在处理器间以消息传递方式进行数据通信和同步，以库函数形式为程序员提 供了一组易于使用的编程接口。 n 93 年由一组来自大学、国家实验室、高性能计算厂商发起组织和研究， 94 年 公布了最早的版本 M PI 1 . 0 ， M PI C H 是 M PI 最流行的非专利实现，目前（ 2023 年） 版本是 M PI C H - 4.1.2 n 特点：提供可靠的、面向消息的通信；在高性能科学计算领域广泛使用，适 合于处理计算密集型的科学计算；独立于语言的编程规范，可移植性好 53 M PI 实现版本 54 开放领域 / 机构实现 M PI C H 阿贡国家实验室和密西西比大学 最早的完整 MP I 标准实现 . LA M O h i o Su p er c om p u t er c en t er M PI C H /N T M i s s i s s i p p i St a t e U n i v er s i t y M PI - FM I l l i n oi s ( M yr i n et ) M PI - AM U C Ber k el e y ( M yr i n et ) M PI - PM RWC P , J a p a n ( M yr i n et ) M PI - CCL C a l i f or n i a I n s t i t u t e of T ec h n ol og y C RI /E PC C M PI C r a y R es ea r c h a n d E d i n b u r g h P a r a l l el C om p u t i n g C en t r e M PI - A P A u s t r a l i a n N a t i on a l U n i v er s i t y - C A P R es ea r c h Pr og r a m ( A P1 0 0 0 ) W3 2 M PI I l l i n oi s , C on c u r r en t Sys t em s RA C E - M PI H u g h es A i r c r a f t C o . M PI - BI P I N RI A , F r a n c e ( M yr i n et ) 厂商实现 HP - M PI H e w l et t P a c k a r d ; C on v e x SPP M PI - F I BM SP1 /SP2 H i t a c h i /M PI Hi t a c h i SG I /M PI SG I P o w er C h a l l en g e s er i es M PI /D E NE C . I N T E L /M PI I n t el . P a r a g on ( iC C lib ) T . M PI T el m a t M u l t i n od e F u j i t s u /M PI F u j i t s u A P1 0 0 0 E PC C /M PI C r a y & E PC C , T 3 D /T 3 E 语言实现 C /C + + Ja v a Pyt h on .N E T M PI 并行程序设计 ¨ 消息传递并行程序设计 ¤ 用户必须通过显式地发送和接收消息来实现处理机间的数据交换。 ¤ 每个并行进程均有自己独立的地址空间，相互之间访问不能直接进行， 必须通过显式的消息传递来实现。 ¨ 并行计算粒度大，特别适合于大规模可扩展并行算法 ¤ 要求用户很好地分解问题，组织不同进程间的数据交换，并行计算粒 度大。 55 M PI 主要功能 ¤ 用常规语言编程方式，所有节点运行同一个程序，但处理不同的数据 ¤ 提供点对点通信 ( P oi n t - p oi n t c om m u n i c a t i on ) l 提供同步通信功能（阻塞通信） l 提供异步通信功能（非阻塞通信） ¤ 提供节点集合通信 ( C ol l ec t i v e c om m u n i c a t i on ) l 提供一对多的广播通信 l 提供多节点计算同步控制 l 提供对结果的规约 ( R ed u c e) 计算功能 ¤ 提供用户自定义的复合数据类型传输 56 M PI 基本程序结构 57 #include < mpi.h > main( int argc , char ** argv ) { int numtasks , rank; MPI_Init (& argc , & argv ); …… …… MPI_Finalize (); exit(0); } MP I 程序头文件 初始化 MP I 环境 并行计算与通信 关闭 MP I 环境 M PI 并行程序设计接口 ¤ 基本编程接口： M PI 提供了 6 个最基本的编程接口，理论上任何并行程序 都可以通过这 6 个基本 A PI 实现 ¨ 1. M PI _I n i t ( argc , argv ) : 初始化 M PI ，开始 M PI 并行计算程序体 ¨ 2. M PI _F i n a l i z e : 终止 M PI 并行计算 ¨ 3. M PI _C om m _S ize ( c om m , s i z e) : 确定指定范围内处理器 / 进程数目 ¨ 4. M PI _C om m _R an k ( c om m , r a nk) : 确定一个处理器 / 进程的标识号 ¨ 5. M PI _S en d ( bu f , c ou n t , d a t a t yp e , d es t , t a g , c om m ) : 发送一个消息 ¨ 6. M PI _R ec v ( bu f , c ou n t , d a t a t yp e , s ou r c e , t a g , c om m , s t a t us ) : 接受消息 ¨ s i z e: 进程数， ra n k ：指定进程的 ID ¨ c om m ：指定一个通信组 ( c om m u n i c a t or ) ¨ d es t ：目标进程号， s ou r c e ：源进程标识号， tag ：消息标签 58 M PI 并行程序设计接口 ¨ M PI 并行计算初始化与结束 n 任何一个 M PI 程序都要用 M PI _I n i t 和 M PI _F i n a l i z e 来指定并行计算开始和结 束的地方；同时在运行时，这两个函 数将完成 M PI 计算环境的初始化设置 以及结束清理工作。处于两者之间的 程序即被认为是并行化的，将在每个 机器上被执行。 59 #include < mpi.h > #include < stdio.h > main( int argc , char ** argv ) { int numtasks , rank; MPI_Init (& argc , & argv ); printf (“Hello parallel world! \\ n”); MPI_Finalize (); exit(0); } Hello parallel world! Hello parallel world! Hello parallel world! Hello parallel world! Hello parallel world! 在一个有 5 个处理器的系统中，输出为： M PI 并行程序设计接口 ¨ 通信组（ C om m u n i c a t or ） ¤ 为了在指定的范围内进行通信，可以将系统中的处理器划分为不同的通信组；一个处理器可 以同时参加多个通信组； M PI 定义了一个最大的缺省通信组 : M PI _C O M M _W O RL D ，指明系统 中所有的进程都参与通信。一个通信组中的总进程数可以由 M PI _C om m _Si z e 调用来确定。 ¨ 进程标识 ¤ 为了在通信时能准确指定一个特定的进程，需要为每个进程分配一个进程标识，一个通信组 中每个进程标识号由系统自动编号（从 0 开始）；进程标识号可以由 M PI _C om m _R a n k 调用来 确定。 60 M PI 并行程序设计接口 ¤ 点对点通信 ¨ 同步通信 ：阻塞式通信，等待通信操作完成后才返回 ¤ M PI _S en d ( bu f , c ou n t , da t a t y pe , de s t , t ag , c om m ) : 发送一个消息 ¤ M PI _R ec v ( bu f , c ou n t , da t a t y pe , s ou r c e , t ag , c om m , s ta tu s ) : 接受消息 ¨ 同步通信时一定要等到通信操作完成，这会造成处理器空闲，因而可能导致系统 效率下降，为此 M PI 提供异步通信功能 ¨ 异步通信 ：非阻塞式通信，不等待通信操作完成即返回 ¤ M PI _ I S en d ( bu f , c ou n t , da t a t y pe , de s t , t ag , c om m , r e qu e s t ) : 异步发送 ¤ M PI _ I R ec v ( bu f , c ou n t , da t a t y pe , s ou r c e , t ag , c om m , s t a t u s , r e qu e s t ) 异步接受消息 ¤ M PI _ W ai t ( r e qu e s t , s t a t u s ) : 等待非阻塞数据传输完成 ¤ M PI _ Te s t ( r e qu e s t , f l ag , s t a t u s ) : 检查是否异步数据传输确实完成 61 M PI 编程示例：简单示例 62 #in c lu d e < mpi . h > #in c lu d e < st d i o . h > in t ma i n ( in t ar g c , c ha r * * ar g v ) { in t num , rk ; MP I _ I n it (& ar g c , & ar g v ); MP I _ C o m m _ s iz e (M P I _ CO M M _ W O R L D , & n u m); MP I _ C o m m _ r a n k (M P I _ CO M M _ W O R L D , & rk ); pr i n t f (“ H e l l o w or l d fro m P ro cess %d of %d \\ n” , rk , num ); M P I _ Fi n a l i z e (); } He l l o w or l d f r om P r oc e s s 0 of 5 He l l o w or l d f r om P r oc e s s 1 of 5 He l l o w or l d f r om P r oc e s s 2 of 5 He l l o w or l d f r om P r oc e s s 3 of 5 He l l o w or l d f r om P r oc e s s 4 of 5 M PI 编程示例：消息传递示例 1 63 # i n c l u d e < st di o . h > # i n c l u d e < mp i . h > int ma i n ( int argc , c ha r ** argv ) { int m yi d , n u m p r oc s , s ou r c e; M PI _St a t u s s t a t u s ; c h a r m es s a g e[ 1 0 0 ] ; M PI _I n i t (& argc , & argv ); M PI _C om m _r a n k ( M PI _C O M M _W O RL D , & m yi d ); M PI _C om m _s i z e ( M PI _C O M M _W O RL D , & n u m p r oc s ); if ( m yi d != 0 ) /* 其他进程，向 0 进程发送 He lloWor ld 信息 */ { st rc p y ( m es s a g e , “ H el l o W or l d ! ” ) ; M PI _Sen d ( m es s a g e , s t r l en ( m es s a g e) + 1 , M PI _C H A R, 0 , 9 9 , M PI _C O M M _W O RL D ) ; } el s e /* 0 进程负责从其他进程接受信息并输出 */ { f or ( s ou r c e = 1 ; s ou r c e < n u m p r oc s ; s ou r c e+ + ) { M PI _R ec v ( m es s a g e , 1 0 0 , M PI _C H A R, s ou r c e , 9 9 , M PI _C O M M _W O RL D , & s t a t u s ) ; pri n tf ( \" I a m p r oc es s % d . I r ec v s t r i n g ' % s ' f r om p r oc es s % d . \\ n\" , m yi d , m es s a g e , s ou r c e ); } } M PI _F i n a l i z e (); } I a m p r oc es s 0 . I r ec v s t r i n g ‘ H el l o W or l d ’ f r om p r oc es s 1 . I a m p r oc es s 0 . I r ec v s t r i n g ‘ H el l o W or l d ’ f r om p r oc es s 2 . I a m p r oc es s 0 . I r ec v s t r i n g ‘ H el l o W or l d ’ f r om p r oc es s 3 . 发送 / 接收消息： He llo W o r ld M PI 编程示例：消息传递示例 2 ¤ 计算大数组元素的开平方之和 ¤ 设系统中共有 5 个进程，进程号： 0 ， 1 ， 2 ， 3 ， 4 ¤ 0 号进程作主节点，负责分发数据，不参加子任务计算 ¤ 1 - 4 号进程作为子节点从主进程接受数组数据： ¤ # 1 : d a t a [ 0 , 4 , 8 , …] ¤ # 2 : d a t a [ 1 , 5 , 9 , …] ¤ # 3 : d a t a [ 2 , 6 , 1 0 , …] ¤ # 4 : d a t a [ 3 , 7 , 1 1 , …] ¤ #0 : Sq r t Su m = ∑ 各子进程的 Sq r t Su m 64 各自求开平方后累加 => 本地 Sq r t Su m M PI 编程示例：消息传递示例 2 65 # i n c l u d e < st di o . h > # i n c l u d e < mp i . h > # i n c l u d e < ma t h . h > # d ef i n e N 1 0 0 2 int ma i n ( int argc , c ha r ** argv ) { int m yi d , P , s ou r c e , C = 0 ; d ou b l e d a t a [ N ] , Sq r t Su m =0 . 0 ; M PI _St a t u s s t a t u s ; c h a r m es s a g e[ 1 0 0 ] ; M PI _I n i t (& argc , & argv ); M PI _C om m _r a n k ( M PI _C O M M _W O RL D , & m yi d ); M PI _C om m _s i z e ( M PI _C O M M _W O RL D , & n u m p r oc s ); - - n u m p r oc s ; / * 数据分配时除去 0 号主节点 * / if ( m yi d == 0 ) { / * 0 号主节点，主要负责数据分发和结果收集 * / f or ( int i = 0 ; i < N; ++ i ) /* 数据分发 : 0 , * / M PI _Sen d (data[ i ] , 1 , M PI _D O U BL E , i % n u m p r oc s + 1 , 1 , M PI _C O M M _W O RL D ) ; f or ( int s ou r c e = 1 ; s ou r c e < = n u m p r oc s ; + + s ou r c e) /* 结果收集 * / { M PI _R ec v ( & d , 1 , M PI _D O U BL E , s ou r c e , 9 9 , M PI _C O M M _W O RL D , & s t a t u s ) ; Sq r t Su m += d ; } } el s e { f or ( i = m yi d - 1; i < N; i = i + n u m p r oc s ) / * 各子节点接受数据计算开平方，本地累加 * / { M PI _R ec v ( & d , 1 , M PI _D O U BL E , 0 , 1 , M PI _C O M M _W O RL D , & s t a t u s ) ; Sq r t Su m +=s q r t ( d ) ; } M PI _Sen d ( Sq r t Su m , 1 , M PI _D O U BL E , 0 , 9 9 , M PI _C O M M _W O RL D ) ; / * 本地累加结果送回主节点 * / } pri n tf ( \" I a m p r oc es s % d . I r ec v t ot a l % d f r om p r oc es s 0 , a n d Sq r t Su m =% f . \\ n\" , m yi d , C , Sq r t Su m ); M PI _F i n a l i z e (); } M PI 编程示例：消息传递示例 3 ¤ M on t e C a r l o 方法计算圆周率 ¤ M on t e C a r l o 是一种随机抽样统计方法，可用于解决难以用数学公式计算结果 的复杂问题近似求解。 ¤ 设 r 取值为 0.5 ，为了提高 π 计算精度，需要计算尽量大的随机点数，我们考虑 在一个并行系统中让每台机器都各自算一个 π ，然后汇总求一个平均值 66 作一个直径为 2r 的圆及其外切正方形，在其 中随机产生 n 个点，落在圆内的点数记为 m 。 根据概率理论，当随机点数足够大时， m 与 n 的比值可近似看成是圆与正方形面积之比。 故有： m /n ≈ π x r 2 /( 2 r ) 2 , π ≈ 4 m /n M PI 编程示例：消息传递示例 3 67 #i n cl u de ” mp i .h ” #i n cl u de < st di o . h > #i n cl u de < st dl i b . h > int ma i n ( int ar g c , c h ar ** ar g v ) { int my i d , num p r o c s ; int na m e le n, s o ur c e ; lo ng c o unt = 1 0 0 0 0 0 0 ; MP I_ S t at u s st a t u s; MP I_ In i t (& ar g c ,& ar g v ); MP I_ C o m m _ r an k (M PI _ C O M M _ W O R L D , & my i d ); MP I_ C o m m _ s i z e (M PI _ C O M M _ W O R L D , & num p r o c s ); sr a n d ( my i d +( int )t im e (0 ) ) ; /* 设置随机种子 */ dou bl e y , x, pi =0 . 0 , n =0 . 0 ; lo ng m = 0 , m 1 = 0 , i= 0 , p = 0 ; fo r ( i =0 ; i < cou n t ; i ++) /* 随机产生一个点 (x , y ) ，判断并计算落在圆内的次数 */ { x = ( d o u b l e) r a n d ( ) / ( d o u b l e) R A N D _ M A X ; y=( do u bl e ) r a n d( ) / ( do u bl e ) R A ND _ M A X ; if((x - 0. 5) *( x - 0. 5) + ( y - 0. 5) *( y - 0. 5) < 0. 25) ++m ; } M PI 编程示例：消息传递示例 3 68 pi =4 . 0 * m / cou n t ; pr i n t f (” Pr o c e s s % d o f % p i= % f \\ n” , my i d , num p r o c s , p i ) ; if( my i d != 0) /* 从节点将本地计算的 π 结果发送到主节点 */ { MP I_ S e n d (& m , 1 , M PI _ D O U B L E , 0 , 1 , M PI _ C O M M _ W O R L D ); } el s e /* 主节点接受各从节点的结果并累加 * / { p = m ; fo r ( s o ur c e = 1 ; s o ur c e < num p r o c s ; s o ur c e ++) { MP I_ R e c v (& m 1 , 1 , M PI _ D O U B L E , s o u r c e , 1 , M PI _ C O M M _ W O R L D , & s t a t u s ); p=p+m 1 ; } pr i n t f (“ p i= % f \\ n” , 4 . 0 * p / ( c o unt * num p r o c s )); /* 各节点输出结果 * / } MP I_ F i n al i z e (); } Pr oc es s 0 of 3 p i = 3 . 1 4 1 3 5 Pr oc es s 1 of 3 p i = 3 . 1 4 3 1 2 Pr oc es s 2 of 3 p i = 3 . 1 4 2 0 3 pi = 3. 14216 ç 汇总平均值 节点集合通信接口 ¨ 提供一个进程与多个进程间同时通信的功能 69 B uf f e r B uf f e r T r a ns m i s s i on S e nd B uf f e r B uf f e r R e c e i ve 节点集合通信接口 ¨ 三种类型的集合通信功能 1. 同步 ( Ba r r i er ) M PI _B ar r i e r ： 设置同步障使所有进程的执行同时完成 2. 数据移动 ( D a t a m ov em en t ) M PI _BC A ST : 一对多的广播式发送 M PI _G A T H E R ：多个进程的消息以某种次序收集到一个进程 M PI _SC A T T E R ：将一个信息划分为等长的段依次发送给其它进程 3. 数据规约 ( R ed u c t i on ) M PI _R e du c e ：将一组进程的数据按照指定的操作方式规约到一起并传送给一个进程 70 节点集合通信接口 ¨ 数据规约操作 将一组进程的数据按照指定的操作方式规约到一起并传送给一个进程 M PI _R e du c e ( s e n db u f , re c v b u f , c ou n t , da t a t y pe , op , r oot , c om m ) ¨ 其中规约操作 op 可设为下表定义的操作之一： M PI _M A X 求最大值 M PI _M I N 求最小值 M PI _SU M 求和 M PI _PRO D 求积 M PI _L A N D 逻辑与 M PI _B A N D 按位与 M PI _L O R 逻辑或 M PI _BO R 按位或 M PI _L X O R 逻辑异或 M PI _BX O R 按位异或 M PI _M A X L O C 最大值和位置 M PI _M I N L O C 最小值和位置 71 节点集合通信接口 ¨ 规约操作编程示例 - 计算积分 根据微积分原理，任一函数 f ( x) 在区间 [ a, b ] 上的积分是由各个 x 处的 y 值为高构成的 N 个小矩形 ( 当 N 趋向无穷大时的）面积之和构成。因此 , 选取足够大的 N 可近似计算积分。 设 y= x 2 ，求其在 [0 , 1 0 ] 区间的积分。 先把 [0 , 1 0 ] 分为 N 个小区间，则对每 个 x 取值对应小矩形面积为： y* 1 0 /N 求和所有矩形面积，当 N 足够大时即 为近似积分值。 72 0 10 我们用 n 个节点来分工计算 N 个区间的面积。如图所示，根据总结点数目，每个 节点将求和一个颜色的小矩形块。 节点集合通信接口 73 #de f i n e N 1 0 0 0 0 0 0 0 0 #de f i n e a 0 #de f i n e b 1 0 #i n cl u de < st di o . h > #i n cl u de < st dl i b . h > #i n cl u de < ti m e . h > #i n cl u de “ mp i .h ” int ma i n ( int ar g c , c h a r * * ar g v ) { int my i d , n u m p r o c s ; int i; dou bl e l oca l =0 . 0 , dx=( dou bl e ) ( b - a) / N ; /* 小矩形宽度 * / dou bl e int e , x ; MP I_ In i t (& ar g c , & ar g v ); MP I_ C o m m _ r an k (M PI _ C O M M _ W O R L D , & my i d ); MP I_ C o m m _ s i z e ( MP I_ C O MM_ W O RL D , & n u m p r o c s ); 节点集合通信接口 74 fo r ( i = my i d ; i < N; i = i+ num p r o c s ) /* 根据节点数目将 N 个矩形分为图示的多个颜色组 * / { /* 每个节点计算一个颜色组的矩形面积并累加 */ x = a + i * dx + dx /2 ; /* 以每个矩形的中心点 x 值计算矩形高度 */ lo c a l + = x * x * dx ; / * 矩形面积 = 高度 x 宽度 =y * dx */ } MP I_ R e d u c e (& lo c a l, & in t e , 1 , M PI _ D O U B L E , MP I_ S U M , 0 , M P I _ C O M M _ WO R L D ) ; if( my i d ==0 ) /* 规约所有节点上的累加和并送到主节点 0 * / { /* 主节点打印累加和 * / pr i n t f (\" T h e int e g a l of x * x i n re gi on [ % d, %d ] = % 1 6 . 1 5 f \\ n\" , a , b , int e ); } MP I_ F i n al i z e (); } T h e i n t eg a l of x* x i n r eg i on [ 0 , 1 0 ] = 3 3 3 . 3 3 3 4 5 M PI 的特点和不足 ¤ MP I 的特点 n 灵活性好，适合于各种计算密集型的并行计算任务 n 独立于语言的编程规范，可移植性好 n 有很多开放机构或厂商实现并支持 ¤ MP I 的不足 n 无良好的数据和任务划分支持 n 缺少分布文件系统支持分布数据存储管理 n 通信开销大，当计算问题复杂、节点数量很大时，难以处理，性能大幅下降 n 无节点失效恢复机制，一旦有节点失效，可能导致计算过程无效 n 缺少良好的构架支撑，程序员需要考虑以上所有细节问题，程序设计较为复杂 75 摘要 ¨ 为什么需要并行计算？ ¨ 并行计算技术的分类 ¨ 并行计算的主要技术问题 ¨ M PI 并行程序设计 ¨ 为什么需要大规模数据并行处理？ 为什么需要海量数据并行处理技术？ ¨ 处理数据的能力大幅落后于数据增长，需要寻找有效的数据密集型并行计算方 法 磁盘容量增长远远快过存储访问带宽和延迟： 80 年代中期数十 MB 到今天 1 - 2T B ，增长 10 万倍， 而延迟仅提高 2 倍，带宽仅提高 50 倍！ ¨ 100T B 数据顺序读一遍需要多少时间？ 设硬盘读取访问速率 1 2 8 M B/ 秒 1 T B/1 2 8 M B 约 2.17 小时 1 0 0 T B/1 2 8 M B = 2 1 7 小时 = 9 天！ 即使用百万元高速磁盘阵列 ( 8 0 0 M B/s ) ，仍需 1.5 天！ 77 ¨ 海量数据隐含着更准确的事实 信息检索、自然语言理解和机器学习的三个要素： 数据，特征，算法 ¨ 2001 ， Ba n k o a n d Br i l l 发表了一篇自然语言领域的经典研究论文， 探讨训练数据集大小对分类精度的影响，发现数据越大，精度越高； 更有趣的发现是，他们发现当数据不断增长时，不同算法的分类精 度趋向于相同，使得小数据集时不同算法在精度上的差别基本消失！ ¨ 结论引起争论：算法不再要紧，数据更重要！不再需要研究复杂算 法，找更多数据就行了！ 78 为什么需要海量数据并行处理技术？ ¨ 海量数据隐含着更准确的事实 ¤ 2001 年，一个基于事实的简短问答研究，如提问： Wh o s h ot A b r a h a m L i n c ol n ？在很大的数 据集时，只要使用简单的模式匹配方法，找到在“ s h ot A b r a h a m L i n c ol n ”前面的部分即可快 速得到准确答案： J oh n Wi l k es Boot h ¤ 2007 ， Br a n t s et a l . 描述了一个基于 2 万亿个单词训练数据集的语言模型，比较了当时最先 进的 K n es er - N e y s m oot h i n g 算法与他们称之为 “s t u p i d b a c k of f “ ( 愚蠢退避 ) 的简单算法，最后 发现，后者在小数据集时效果不佳，但在大数据集时，该算法最终居然产生了更好的语言 模型！ ¨ 结论：大数据集上的简单算法能比小数据集上的复杂算法 产生更好的结果！ 79 为什么需要海量数据并行处理技术？为什么需要 M a p R ed u c e ？ ¨ 并行计算技术和并行程序设计的复杂性 依赖于不同类型的计算问题、数据特征、计算要求、和系统构架，并行计算 技术较为复杂，程序设计需要考虑数据划分，计算任务和算法划分，数据访问 和通信同步控制，软件开发难度大，难以找到统一和易于使用的计算框架和编 程模型与工具。 ¨ 海量数据处理需要有效的并行处理技术 海量数据处理时，依靠 M PI 等并行处理技术难以凑效 ¨ M a p R ed u c e 是目前面向海量数据处理最为成功的技术 M a p R ed u c e 是目前业界和学界公认的最为有效和最易于使用的海量数据并行处 理技术 G oog l e ， I BM ， A m a z on ，百度等国内外公司普遍使用 80 M a p R ed u c e 简介 ¨ 问题与需求： 如何对巨量的 We b 文档建立索引、根据网页链接计算网页排名，从上百 万文档中训练垃圾邮件过滤器，运行气象模拟，数十亿字符串的排序？ ¨ 解决方案： 如果你想学习如果编写程序完成这些巨量数据的处理问题， M a p R ed u c e 将 为你提供一个强大的分布式计算环境和构架，让你仅需关注你的应用问题本身，编写 很少的程序代码即可完成看似难以完成的任务！ ¨ 什么是 M a p R ed u c e ？ M a p R ed u c e 是 G oog l e 公司发明的一种面向大规模海量数据处理的 高性能并行计算平台和软件编程框架，是目前最为成功和最易于使用的大规模海量数 据并行处理技术，广泛应用于搜索引擎（文档倒排索引，网页链接图分析与页面排序 等）、 We b 日志分析、文档分析处理、机器学习、机器翻译等各种大规模数据并行计 算应用领域。 81 M a p R ed u c e 简介 M a p R ed u c e 是面向大规模数据并行处理的： ¨ 基于集群的高性能并行计算平台 ( C l u s t er I n f r a s t r u c t u r e) 允许用市场上现成的普通 PC 或性能较高的刀架或机架式服务器，构成一个包含数千个节点的分布式并行 计算集群 ¨ 并行程序开发与运行框架 ( Sof t w a r e F r a m e w or k ) 提供了一个庞大但设计精良的并行计算软件构架，能自动完成计算任务的并行化处理，自动划分计算数 据和计算任务，在集群节点上自动分配和执行子任务以及收集计算结果，将数据分布存储、数据通信、 容错处理等并行计算中的很多复杂细节交由系统负责处理，大大减少了软件开发人员的负担 ¨ 并行程序设计模型与方法 ( Pr og r a m m i n g M od el & M et h od ol og y) 借助于函数式语言中的设计思想，提供了一种简便的并行程序设计方法，用 Ma p 和 R ed u c e 两个函数编程 实现基本的并行计算任务，提供了完整的并行编程接口，完成大规模数据处理 82 G oog l e M a p R ed u c e ¨ 2004 年， G oog l e 在 O SD I 国际会议上发表了一篇论文： “ M apR e du c e : Si m pl i f i e d Da t a Pr oc e s s i n g on L ar g e Cl u s t e r s ” ，公布了 M a p R ed u c e 的基本原理和主要设 计思想。 ¨ G oog l e 公司用 M a p R ed u c e 重新改写了其整个搜索引擎中的 We b 文档索引处理 ¨ 自 M a p R ed u c e 发明后， G oog l e 大量用于各种海量数据处理， 2006 年 7 月统计 G oog l e 内部有 7 千 以上的程序基于 M a p R ed u c e 实现 83 G oog l e M a p R ed u c e ¨ 巨大的 We b 搜索引擎和海量数据并行处理硬件平台 G oog l e 目前在全球的数十个数据中心使用了百万台以上的服务器构成其强大的 We b 搜索和海 量数据并行计算平台，支撑其搜索引擎、 Gm ai l 、 G oog l e M a p 、 G oog l e E a r t h 、以及其云计算平 台 Ap p E n g i n e 的大型应用服务需求。 ¨ 强大的数据处理服务能力 G oog l e 可提供超过 80 亿网页和 10 亿张图片的检索索引，每天处理 2 亿次以上检索请求，平均 每个检索耗时 0. 5 秒；每个搜索请求背后有上千个服务器同时进行检索计算和服务 84 H a d oop M a p R ed u c e 简介 ¨ 在 G oog l e 发表了文章后， D ou g C u t t i n g ， 2004 年，开源项目 L u c en e( 搜索索引程 序库 ) 和 Nutc h ( 搜索引擎 ) 的创始人，发现 M a p R ed u c e 正是其所需要的解决大规模 分布数据处理的重要技术，因而模仿 G oog l e M a p R ed u c e ，基于 Ja v a 设计出了称 为 H a d oop 的开源 M a p R ed u c e ，该项目成为 Apac h e 下最重要的项目 ¨ Apac h e H a d oop 目前的最新版本是 3.3.4 （ Au g 8 , 2 0 2 2 ） 85 为什么 M a p R ed u c e 很重要？ ¨ Wh y i s M a p R ed u c e i m p or t a n t ? I n p r a c t i c a l t er m s , i t p r ov i d es a v er y ef f ec t i v e t ool f or t a c k l i n g l a r g e - d a t a p r ob l em s . ¨ Bu t b e y on d t h a t , M a p R ed u c e i s i m p or t a n t i n h o w i t h a s c h a n g ed t h e w a y w e or g a n i z e c om p u t a t i on s a t a m a s s i v e s c a l e . ¨ M a p R ed u c e r ep r es en t s t h e f i r s t w i d el y - a d op t ed s t ep a w a y f r om t h e v on N eu m a n n m od el . M a p R ed u c e c a n b e v i e w ed a s t h e f i r s t b r ea k t h r ou g h i n t h e q u es t f or n e w a b s t r a c t i on s t h a t a l l o w u s t o or g a n i z e c om p u t a t i on s , n ot ov er i n d i v i d u a l m a c h i n es , b u t ov er en t i r e c l u s t er s . ¨ M a p R ed u c e i s t h e m os t s u c c es s f u l a b s t r a c t i on ov er l a r g e - s c a l e c om p u t a t i on a l r es ou r c es w e h a v e s een t o d a t e . 86 Ci t e f r om J i m m y L i n , Un i v er s i t y of M a r y l a n d , D a t a - In t e n s i v e T e x t p r o c e s s i n g w i t h M a p R e d u c e ， 2010 TH A NK YO U","libVersion":"0.2.4","langs":""}