{"path":"课程/金融大数据/课件/05 Hadoop基本架构.pdf","text":"H a d oop 基本架构 摘要 ¨ H a d oop 平台的基本组成与生态系统 ¨ 分布式文件系统 HDF S ¨ H a d oop M a p R ed u c e 的基本工作原理 官网： h t t p s: / / h a d o o p . a p a ch e . o r g 官方文档 h t t p s: / / h a d o o p . a p a ch e . o r g / d o cs/ st a b l e / i n d e x. h t m l 摘要 ¨ H a d oop 平台的基本组成与生态系统 ¨ 分布式文件系统 HDF S ¨ H a d oop M a p R ed u c e 的基本工作原理 H a d oop 简介 • H a d oop 是 Ap a c h e 软件基金会旗下的一个开源分布式计算平台，为 用户提供了系统底层细节透明的分布式基础架构 。 • H a d oop 是基于 Ja v a 语言开发的，具有很好的跨平台特性，并且可 以部署在廉价的计算机集群中 。 • H a d oop 的核心是分布式文件系统 HDF S （ H a d oop D i s t r i b u t ed F i l e Sys t em ）和 M a p R ed u c e 。 • H a d oop 被公认为行业大数据标准开源软件，在分布式环境下提供 了海量数据的处理能力 。 4 H a d oop 特性 ¨ H a d oop 是一个能够对大量数据进行分布式处理的软件框架，并且是以一种 可 靠、高效、可伸缩 的方式进行处理的，它具有以下几个方面的特性： • 高可靠性 • 高效性 • 高可扩展性 • 高容错性 • 成本低 • 运行在 Li n u x 平台上 • 支持多种编程语言 5 H a d oop 基本组成和生态系统 6 分布式存储和并行计算集群Hadoop 生 态 系 统 与 支 撑 平 台 分 布 式 协 调 服 务 器 框 架Zookeeper 公共服务模块 C om m on 数据序列化系统 Av r o 分布式海量数据存储 分布式文件系统 HDFS 分布式数据库管理系统 H B a se M a p R ed u c e 并行计算框架 数据流处理工具 Pi g 数据仓库处理工具 Hi v e 健值对数据库系统 Cassan dr a 日志数据处理系统 Ch u k w a 科学计算基础工具库 Ha m a 数据分析挖掘工具库 M a h ou t 关系数据交换工具 Sq oop 日志数据收集工具 Fl ume 其它第三方工具 H a d oop 基本组成和生态系统 7 Ha d o o p 1. x 架构 H a d oop 基本组成和生态系统 8 Ha d o o p 2. x 架构 H a d oop 基本组成和生态系统 9 组件 功能 HDF S 分布式文件系统 M a p R e d u ce 分布式并行编程模型 YA R N 资源管理和调度器 Te z 运行在 YA R N 之上的下一代 Ha d o o p 查询处理框架 H i ve Ha d o o p 上的数据仓库 H B a se Ha d o o p 上的非关系型的分布式数据库 Pi g 一个基于 Ha d o o p 的大规模数据分析平台，提供类似 SQ L 的查询语言 Pi g L a t i n Sq o o p 用于在 Ha d o o p 与传统数据库之间进行数据传递 O o zi e Ha d o o p 上的工作流管理系统 Z o o ke e p e r 提供分布式协调一致性服务 St o r m 流计算框架 Fl u m e 一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统 Am b a r i Ha d o o p 快速部署工具，支持 A p a ch e H a d o o p 集群的供应、管理和监控 K a f ka 一种高吞吐量的分布式发布订阅消息系统，可以处理消费者规模的网站中的所有动作流数据 Sp a r k 类似于 H a d o o p M a p R e d u ce 的通用并行框架 常见大数据应用系统架构 10 We b 服务器 fl u m e M a p R ed u c e Hi v e Sq oop H Ba s e We b UI HDF S 日志收集 日志存储 数据批处理 数据挖掘 数据导出 数据存储 数据可视化 H a d oop 在企业中的应用架构 11 H a d oop 各种发行版 ¨ A p a c h e H a d oop ¨ H or t on w or k s ¨ C l ou d er a （ CDH ： C l ou d er a D i s t r i b u t i on H a d oop ） ¨ MapR ¨ …… 12 H a d oop 各种发行版 13 阿里云飞天平台的系统架构 14 摘要 ¨ H a d oop 平台的基本组成与生态系统 ¨ 分布式文件系统 HDF S ¨ H a d oop M a p R ed u c e 的基本工作原理 G oog l e GF S 的基本设计原则 ¨ G oog l e G F S 是一个基于 分布式集群 的大型分布式文件系统， 为 M a p R ed u c e 计算框架提供 数据存储和数据可靠性支撑 ； ¨ GF S 是一个构建在分布节点本地文件系统之上的一个逻辑 上文件系统，它将数据存储在物理上分布的每个节点上， 但 通过 GF S 将整个数据形成一个逻辑上整体的文件 。 16 HDF S 的基本特征 ¨ 模仿 G oog l e G F S 设计实现 ¨ 存储极大数目的信息（ t er a b yt es or p et a b yt es ），将数据保存到大量的节点当 中；支持很大的单个文件。 ¨ 提供数据的高可靠性和容错能力，单个或者多个节点不工作，对系统不会造成 任何影响，数据仍然可用。通过一定数量的数据复制保证数据存储的可靠性和 出错恢复能力。 ¨ 提供对数据的快速访问；并提供良好的可扩展性，通过简单加入更多服务器快 速扩充系统容量，服务更多的客户端。 ¨ 与 GFS 类似， HDF S 是 M a p R ed u c e 的底层数据存储支撑，并使得数据尽可能根据 其本地局部性进行访问与计算。 17 HDF S 的基本特征 ¨ HDF S 对顺序读进行了优化，支持大量数据的快速顺序读出，代价是对于随机 的访问负载较高。 ¨ 数据支持一次写入，多次读取；不支持已写入数据的更新操作。 ¨ 数据不进行本地缓存（文件很大，且顺序读没有局部性） ¨ 基于块的文件存储，默认的块的大小是 64MB n 减少元数据的量 n 有利于顺序读写（在磁盘上数据顺序存放） ¨ 多副本数据块形式存储，按照块的方式随机选择存储节点，默认副本数目是 3 18 HDF S 基本构架 19 TC P Soc k et I PC ( H a d oop RPC ) HDF S ( C l i e n t Pr ot oc ol , D a t aN ode Pr ot oc ol ) ( N a m eN od e , D a t a N od e , D F SC l i en t ) Ab s t r a ct F i l eSys t em M a p R ed u c e Ap p M a p R ed u c e F r a m e w or k Ap p . JM X HDF S 基本构架 20 对等于 GF S M a s t er 对等于 GF S C h u n k Ser v er 应用程序 HDFS 客户端 文件名或数据块号 数据块号，数据块位置 H D F S N a m eN od e D a t a N od e 数据 D a t a N od e 数据 D a t a N od e 数据 HDF S 基本构架 21 N a m eN od e • 在 HDF S 中，名称节点（ N a m eN od e ）负责管理分布式文件系统的 命名空间（ N a m es p a c e ），保存了两个核心的数据结构，即 Fs I m a g e 和 E d i t L og • Fs Im a g e 用于维护文件系统树以及文件树中所有的文件和文件夹的元数据 • 操作日志文件 E d i t L og 中记录了所有针对文件的创建、删除、重命名等操作 • 名称节点记录了每个文件中各个块所在的数据节点的位置信息 22 N a m eN od e ¨ N a m eN od e 目录结构 23 1 ） C u r r en t 目录主要包含如下的内容： • 文件 V er s i on ：保存当前运行的 hd f s 版本信息 • Fs I ma g e ：整个系统的空间镜像文件，它是 在 N a m eN od e 启动时对整个文件系统的快照 • Ed i t ： E d i t L og 编辑日志 ，它是 在 N a m eN od e 启 动后，对文件系统的改动 序列 2 ） i n _u s e . l oc k ： N a m eN od e 锁。只有在 N a m eN od e 有效（启动并且能和 D a t a N od e 正常 交互）时存在。不满足上述情况时，该文件不 存在。这一文件具有“锁”的功能，可以防止 多个 N a m eN od e 共享同一目录。 N a m eN od e 24 名 称 节 点 ( NameNode) F sIm age E ditL og 根 目 录 目 录 目 录 目 录 文 件 块 … 块 记 录 了 所 有 针 对 文 件 的 创 建 、 删 除 、 重 命 名 等 操 作 N a m eN od e ¨ Fs I m a g e 文件 • Fs Ima g e 文件包含文件系统中所有目录和文件 i n od e 的序列化形式。每个 i n od e 是一个文件或目录的元数据的内部表示，并包含此类信息：文件的复制等 级、修改和访问时间、访问权限、块大小以及组成文件的块。对于目录， 则存储修改时间、权限和配额元数据。 • Fs Ima g e 文件没有记录文件包含哪些块以及每个块存储在哪个数据节点。而 是由名称节点把这些映射信息保留在内存中，当数据节点加入 HDF S 集群时， 数据节点会把自己所包含的块列表告知给名称节点，此后会定期执行这种 告知操作，以确保名称节点的块映射是最新的。 25 N a m eN od e ¨ 启动过程 • 在名称节点启动的时候，它会将 Fs Im a g e 文件中的内容加载到内存中，之后再执行 E d i t L og 文 件中的各项操作，使得内存中的元数据和实际的同步，存在内存中的元数据支持客户端的 读操作。 • 一旦在内存中成功建立文件系统元数据的映射，则创建一个新的 Fs Im a g e 文件和一个空的 E d i t L og 文件。 • 名称节点起来之后， HDF S 中的更新操作会重新写到 E d i t L og 文件中，因为 Fs Im a g e 文件一般都 很大（ GB 级别的很常见），如果所有的更新操作都往 Fs Im a g e 文件中添加，这样会导致系统 运行的十分缓慢，但是，如果往 E d i t L og 文件里面写就不会这样，因为 E d i t L og 要小很多。每 次执行写操作之后，且在向客户端发送成功代码之前， ed i t s 文件都需要同步更新。 26 N a m eN od e ¨ 名称节点运行期间 Edi t Log 不断变大的问题 • 在名称节点运行期间， HDF S 的所有更新操作都是直接写到 E d i t L og 中，久而 久之， E d i t L og 文件将会变得很大。 • 虽然这对名称节点运行时候是没有什么明显影响的，但是，当名称节点重 启的时候，名称节点需要先将 Fs Ima g e 里面的所有内容映像到内存中，然后 再一条一条地执行 E d i t L og 中的记录，当 E d i t L og 文件非常大的时候，会导致名 称节点启动操作非常慢，而在这段时间内 HDF S 系统处于安全模式，一直无 法对外提供写操作，影响了用户的使用。 27 Sec on d a r yN a m eN od e ¨ Se c o n d ar y N am e N o d e 是 HDF S 架构中的一个组成部分，它是用来 保存名称节点中对 H D F S 元数据信息的备份，并减少名称节点重 启的时间。 Sec on d a r yN a m eN od e 一般是单独运行在一台机器上。 28 Sec on d a r yN a m eN od e ¨ Sec on d a r yN a m eN od e 目录结构 29 Sec on d a r yN a m eN od e 30 • S e co n d a r yN a m e N o d e 会定期和 Na me No d e 通信 • 从 Na me No d e 上获取到 F sI m a g e 和 Edi tLog 文件，并 下载到本地的相应目录下 • 执行 Edi tLog 和 F sI m a g e 文件合并 • 将新的 F sI m a g e 文件发送到 Na me No d e 节点上 • Na me No d e 使用新的 F sI m a g e 和 Edi tLog （缩小了） 第二名称节点用途： • 不是热备份 • 主要是 防止日志文件 Edi tLog 过大，导致名称节点失 败恢复时消耗过多时间 • 附带起到冷备份功能 D a t a N od e • 数据节点是分布式文件系统 HDF S 的工作节点，负责数据的存储和 读取，会根据客户端或者是名称节点的调度来进行数据的存储和 检索，并且向名称节点定期发送自己所存储的块的列表。 • 每个数据节点中的数据会被保存在各自节点的本地 Li n u x 文件系统 中。 31 D a t a N od e ¨ D a t a N od e 目录结构 32 C u r r en t 目录：已经成功写入 的数据块，以及一些系统需 要的文件。包括： • 文件 V E RSI O N • BP - xxxxx ：数据块和数据 块对应的元数据 HDF S 命名空间管理 ¨ HDF S 的命名空间包含目录、文件和块。 ¨ 在 H D F S1 . 0 体系结构中，在整个 HDF S 集群中只有一个命名空间， 并且只有唯一一个名称节点，该节点负责对这个命名空间进行管 理。 ¨ HDF S 使用的是传统的分级文件体系，因此，用户可以像使用普通 文件系统一样，创建、删除目录和文件，在目录间转移文件，重 命名文件等。 33 HDF S 通信协议 ¨ HDF S 是一个部署在集群上的分布式文件系统，因此，很多数据需要 通过网络进行传输。 ¨ 所有的 HDF S 通信协议都是构建在 T C P/I P 协议基础之上的 ¨ 客户端通过一个可配置的端口向名称节点主动发起 TC P 连接，并使 用客户端协议与名称节点进行交互。 ¨ 名称节点和数据节点之间则使用数据节点协议进行交互。 ¨ 客户端与数据节点的交互是通过 RPC （ R em ot e Pr oc ed u r e C a l l ） 来实 现的。在设计上，名称节点不会主动发起 RPC ， 而是响应来自客户 端和数据节点的 RPC 请求。 34 HDF S 客户端 ¨ 客户端是用户操作 HDF S 最常用的方式， HDF S 在部署时都提供了客 户端。 ¨ HDF S 客户端是一个库，暴露了 HDF S 文件系统接口，这些接口隐藏 了 HDF S 实现中的大部分复杂性。 ¨ 严格来说，客户端并不算是 HDF S 的一部分。 ¨ 客户端可以支持打开、读取、写入等常见的操作，并且提供了类似 Sh el l 的命令行方式来访问 HDF S 中的数据。 ¨ 此外， HDF S 也提供了 J a v a A PI ， 作为应用程序访问文件系统的客户 端编程接口。 35 HDF S 数据分布设计 36 多副本数据块形式存储，按照块的方式随机选择存储节点 默认副本数目是 3 HDF S 数据分布设计 37 数据存取策略 ¨ 数据存放 ¤ 第一个副本：放置在上传文件的数据节点；如果是集群外提交，则随 机挑选一台磁盘不太满、 C PU 不太忙的节点 ¤ 第二个副本：放置在与第一个副本不同的机架的节点上 ¤ 第三个副本：与第一个副本相同机架的其他节点上 ¤ 更多副本：随机节点 38 数据存取策略 ¨ 数据读取 ¤ HDF S 提供了一个 A PI 可以确定一个数据节点所属的机架 ID ， 客户端也可 以调用 A PI 获取自己所属的机架 ID （ Ra c k A w a r en es s ） 。 ¤ 当客户端读取数据时，从名称节点获得数据块不同副本的存放位置列 表，列表中包含了副本所在的数据节点，可以调用 A PI 来确定客户端和 这些数据节点所属的机架 ID ， 当发现某个数据块副本对应的机架 ID 和 客户端对应的机架 ID 相同时，就优先选择该副本读取数据，如果没有 发现，就随机选择一个副本读取数据。 39 HDF S 读过程 40 HDF S 读过程 41 import java.io.BufferedReader ; import java.io.InputStreamReader ; import org.apache.hadoop.conf.Configuration ; import org.apache.hadoop.fs.FileSystem ; import org.apache.hadoop.fs.Path ; import org.apache.hadoop.fs.FSDataInputStream ; public class ReadHdfsFile { public static void main ( String [] args ) { try { Configuration conf = new Configuration (); conf.set (\"fs. defaultFS \",\" hdfs ://localhost:9000\"); conf.set (\"fs.hdfs. impl \",\" org.apache.hadoop.hdfs.DistributedFileSystem \"); FileSystem fs = FileSystem.get ( conf ); Path file = new Path (\"test\"); FSDataInputStream getIt = fs.open (file); BufferedReader d = new BufferedReader ( new InputStreamReader ( getIt )); String content = d.readLine (); // 读取文件一行 System.out.println ( content ); d.close (); // 关闭文件 fs.close (); // 关闭 hdfs } catch ( Exception e) { e.printStackTrace (); } } } HDF S 读过程 42 客户端JVM HDFS 客户端 Di stri buted Fi l eSystem FSDataInput Stream 名称节点 数据节点 数据节点 数据节点 4:读取数据 6:读取数据 客户端节点 1：打开文件 2：获取数据块信息 5：获取数据块信息 （可能发生） 3：读取请求 7： 关 闭 文 件 FS D a t a I n p u t S t r e a m 封装了 DF S I n p u t S t r e a m F i l e S yst e m f s = F i l e S yst e m . g e t ( co n f ) ; FS D a ta In p u tS tr e a m in = f s. o p e n (n e w P a t h ( ur i )); C o n f i g u r a t i o n co n f = n e w C o n f i g u r a t i o n ( ) ; im p o r t o r g . a p a ch e . h a d o o p . f s. F i l e S yst e m 通过 C l i e n t P r o t o ca l . g e t B l o ckL o ca t i o n s () 远程调用名称节点，获得文件开始部分数据块的位置 对于该数据块，名称节点返回保存该数据块 的所有数据节点的地址 并根据距离客户端远近进行排序 客户端获得输入流 FS D a ta In p u tS tr e a m 以后 调用 re a d () 函数开始读取数据 输入流根据前面的排序结果 选择距离客户端最近的数据节点 建立连接并读取数据 数据从数据节点读到客户端，当该数据块读取完毕时 FS D a ta In p u tS tr e a m 关闭和该数据节点的连接 通过 C l i e n t P r o t o ca l . g e t B l o ckL o ca t i o n s( ) 查找下一个数据块 HDF S 写过程 43 HDF S 写过程 44 import org.apache.hadoop.conf.Configuration ; import org.apache.hadoop.fs.FileSystem ; import org.apache.hadoop.fs.FSDataOutputStream ; import org.apache.hadoop.fs.Path ; public class WriteHdfsFile { public static void main (String[] args ) { try { Configuration conf = new Configuration (); conf.set (“fs. defaultFS ”,“ hdfs ://localhost:9000”); conf.set (\"fs.hdfs. impl \",\" org.apache.hadoop.hdfs.DistributedFileSystem \"); FileSystem fs = FileSystem.get ( conf ); byte [] buff = \"Hello world \". getBytes (); // 要写入的内容 String filename = \"test\"; // 要写入的文件名 FSDataOutputStream os = fs.create ( new Path ( filename )); os.write (buff,0,buff.length); System.out.println (\" Create :\"+ filename ); os.close (); fs.close (); } catch ( Exception e) { e.printStackTrace (); } } } HDF S 写过程 45 客户端JVM HDFS 客户端 Di stri buted Fi l eSystem FSData OutputStream 名称节点 数据节点 数据节点 数据节点 客户端节点 4 4 55 5:接收确认包4:写入数据包 2：创建文件元数据 7：写操作完成 1：创建文件请求 3：写入数据 6 ： 关 闭 文 件 F i l e S yst e m f s = F i l e S yst e m . g e t ( co n f ) ; F S D a t a O u t p u t S t r e a m o u t = f s. cr e a t e ( n e w P a t h ( u r i ) ) ; C o n f i g u r a t i o n co n f = n e w C o n f i g u r a t i o n ( ) ; i m p o r t o r g . a p a ch e . h a d o o p . f s. F i l e S yst e m RP C 远程调用名称节点 在文件系统的命名空间中新建一个文件 名称节点会执行一些检查（文件是否存在，客户端权限） FS D a t a O u t p u t S t r e a m 封装了 DF S O u t p u t S t r e a m 数据被分成一个个分包 分包被放入 DF S O u t p u t S t r e a m 对象的内部队列 DF S O u t p u t S t r e a m 向名称节点申请 保存数据块的若干数据节点 这些数据节点形成一个数据流管道 队列中的分包最后被打包成数据包 发往数据流管道中的第一个数据节点 第一个数据节点将数据包发送到第二个节点 依此类推，形成“流水线复制” 为了保证节点数据准确，接收到数据的数据节点要向发送者发送“确认包” 确认包沿着数据流管道逆流而上，经过各个节点最终到达客户端 客户端收到应答时，它将对应的分包从内部队列移除 DF S O u t p u t S t r e a m 调用 C l i e n t P r o t o ca l . co m p l e t e ( ) 方法 通知名称节点关闭文件 HDF S 数据读写过程 • F i l eSys t em 是一个通用文件系统的抽象基类，可以被分布式文件系统继承，所 有可能使用 H a d oop 文件系统的代码，都要使用这个类。 • H a d oop 为 F i l eSys t em 这个抽象类提供了多种具体实现。 • D i s t r i b u t ed F i l eSys t em 就是 F i l eSys t em 在 HDF S 文件系统中的具体实现。 • F i l eSys t em 的 op en ( ) 方法返回的是一个输入流 F SD a t a I n p u t St r ea m 对象，在 HDF S 文 件系统中，具体的输入流就是 D F SI n p u t St r ea m ； F i l eSys t em 中的 c r ea t e( ) 方法返回 的是一个输出流 F SD a t a O u t p u t St r ea m 对象，在 HDF S 文件系统中，具体的输出流 就是 D F SO u t p u t St r ea m 。 46 HDF S 可靠性与出错恢复 ¨ D a t a N od e 节点的检测 ¤ 心跳： N a m eN od e 不断检测 D a t a N od e 是否有效 ¤ 若失效，则寻找新的节点替代，将失效节点数据重新分布 ¨ 集群负载均衡 ¨ 数据一致性：校验和 ( c h ec k s u m ) ¨ 主节点元数据失效 ¤ M u l t i p l e Fs I m ag e and E d i t L og ¤ C h ec k p oi n t 47 N a m eN od e 出错 ¨ 名称节点保存了所有的元数据信息，其中，最核心的两大数据结构 是 Fs Im a g e 和 E d i t l og ， 如果这两个文件发生损坏，那么整个 HDF S 实例 将失效。 ¨ 因此， HDF S 设置了备份机制，把这些核心文件同步复制到备份服务 器 Sec on d a r yN a m eN od e 上。当名称节点出错时，就可以根据备份服 务器 Sec on d a r yN a m eN od e 中的 Fs Im a g e 和 E d i t l og 数据进行恢复。 48 D a t a N od e 出错 ¨ 每个数据节点会定期向名称节点发送“心跳”信息，向名称节点报告自己的状态。 ¨ 当数据节点发生故障，或者网络发生断网时，名称节点就无法收到来自一些数据节点 的心跳信息，这时，这些数据节点就会被标记为“宕机”，节点上面的所有数据都会 被标记为“不可读”，名称节点不会再给它们发送任何 I /O 请求。 ¨ 这时，有可能出现一种情形，即由于一些数据节点的不可用，会导致一些数据块的副 本数量小于冗余因子。 ¨ 名称节点会定期检查这种情况，一旦发现某个数据块的副本数量小于冗余因子，就会 启动数据冗余复制，为它生成新的副本。 ¨ HDF S 和其它分布式文件系统的最大区别就是可以调整冗余数据的位置。 49 数据出错 ¨ 网络传输和磁盘错误等因素，都会造成数据错误。 ¨ 客户端在读取到数据后，会采用 md5 和 sh a1 对数据块进行校验，以确定读取到 正确的数据。 ¨ 在文件被创建时，客户端就会对每一个文件块进行信息摘录，并把这些信息写 入到同一个路径的隐藏文件里面。 ¨ 当客户端读取文件的时候，会先读取该信息文件，然后，利用该信息文件对每 个读取的数据块进行校验，如果校验出错，客户端就会请求到另外一个数据节 点读取该文件块，并且向名称节点报告这个文件块有错误，名称节点会定期检 查并且重新复制这个块。 50 H a d oop v 2 . x v s . H a d oop v 3 . x Ha d o o p 2. x Ha d o o p 3 .x JDK Ja v a 7 + Ja v a 8 + 容错 复制 Er a s ur e 编码 存储 200% 开销 50% 开销 Y A RN 时间线服务 可伸缩的旧时间轴服务 改进时间线服务 v2 兼容的文件系统 HDF S ， FTP ， A m a z on S3 ， W A SB + 微软 A z u r e D a t a L a k e N a m eN od e 2 个 2 个或更多个 51 HDF S 纠删码（ Er asure C od i n g ） ¨ 目的：提高存储利用率，保证数据可靠性 ¨ 纠删码技术（ E r a s u r e c od i n g ） 简称 EC ， 是一种编码容错技术。最 早用于通信行业，数据传输中的数据恢复。它通过对数据进行分 块，然后计算出校验数据，使得各个部分的数据产生关联性。当 一部分数据块丢失时，可以通过剩余的数据块和校验块计算出丢 失的数据块。 52 HDF S 纠删码（ Er asure C od i n g ） ¨ R eed - Sol om on （ RS ） 码是存储系统较为常用的一种纠删码，它有两个参数 k 和 m ， 记为 RS( k ， m) 。 如下图所示， k 个数据块组成一个向量被乘上一个生成矩阵 （ G en er a t or M a t r i x ） GT 从而得到一个码字（ c od e w or d ） 向量，该向量由 k 个数 据块和 m 个校验块构成。如果一个数据块丢失，可以用 ( GT) - 1 乘以码字向量来 恢复出丢失的数据块。 RS( k ， m) 最多可容忍 m 个块（包括数据块和校验块）丢 失。 53 HDF S 纠删码（ Er asure C od i n g ） ¨ 优势：节约存储空间 ¨ 劣势： ¤ 网络带宽的消耗，因为数据恢复需要去读其他的数据块和校验块 ¤ 进行编码，解码计算需要消耗 C PU 资源 ¨ 最好的选择是用于冷数据集群 ¤ 冷数据集群往往有大量的长期没有被访问的数据，体量确实很大，采用 EC 技术，可以大大减少副本数 ¤ 冷数据集群基本稳定，耗资源量少，所以一旦进行数据恢复，将不会对集 群造成大的影响 54 HDF S EC 方案 ¨ 传统模式下 HDF S 中文件的基本构成单位是 b l oc k ， 而 EC 模式下文件的基本构成 单位是 b l oc k g r ou p 。 以 RS( 3 , 2 ) 为例，每个 b l oc k g r ou p 包含 3 个数据块， 2 个校验 块。 ¨ 连续布局（ C on t i g u ou s L a y ou t ） ¤ 文件数据被依次写入块中，一个块写满之后再写入下一个块，这种分布方式称为连续布局。 ¤ 优点：容易实现；方便和多副本存储策略进行转换 ¤ 缺点：需要客户端缓存足够的数据块；不适合存储小文件 55 HDF S EC 方案 ¨ 条形布局（ St r i p i n g L a y ou t ） ¤ 条（ st ri pe ） 是由若干个相同大小的单元（ c el l ） 构成的序列。文件数据被依次写入条的各个 单元中，当一个条写满之后再写入下一个条，一个条的不同单元位于不同的数据块中。这 种分布方式称为条形布局。 ¤ 优点：客户端缓存数据较少；无论文件大小都适用 ¤ 缺点：会影响一些位置敏感任务的性能，因为原先在一个节点上的块被分散到了多个不同 的节点上；和多副本存储策略转换比较麻烦 56 HDF S HA ¨ H D F S H A （ H i g h A v a i l a b i l i t y ） 是为了解决单点故障问题 ¨ HA 集群设置两个名称节点，“活跃（ Acti v e ）” 和“待命（ St a n d b y ）” ¨ 两种名称节点的状态同步，可以借助于一个共享存储系统来实现 ¨ 一旦活跃名称节点出现故障，就可以立即切换到待命名称节点 ¨ Zook eep er 确保一个名称节点在对外服务 ¨ 名称节点维护映射信息，数据节点同时向两个名称节点汇报信息 57 HDF S HA 58 Zookeeper 故障恢复控制器 （活跃） 故障恢复控制器 （待命） 名称节点 （活跃） 名称节点 （待命） 心跳 心跳 监控名称节点 健康状态 监控名称节点 健康状态 命令 共享存储系统 （NFS、QJM或Zookeeper） 数据 节点 ... 向名称节点汇报自己保存的块信息 Zookeeper Zookeeper 数据 节点 数据 节点 向名称节点汇报自己保存的块信息 命令 ... HDF S HA 架构 摘要 ¨ H a d oop 平台的基本组成与生态系统 ¨ 分布式文件系统 HDF S ¨ H a d oop M a p R ed u c e 的基本工作原理 经典版的 M a p R ed u c e 架构（ v1.0 ） 60 对等于 G oog l e M a p R ed u c e 中的 M a s t er 对等于 G oog l e M a p R ed u c e 中的 W or k er 经典版的 M a p R ed u c e 架构（ v1.0 ） 61 经典版的 M a p R ed u c e 架构（ v1.0 ） 62 经典版的 M a p R ed u c e 架构（ v1.0 ） 63 da t a node da e m on L i n u x f i l e syst e m … ta s k tr a c k e r sl ave n o d e da t a node da e m on L i n u x f i l e syst e m … ta s k tr a c k e r sl ave n o d e da t a node da e m on L i n u x f i l e syst e m … ta s k tr a c k e r sl ave n o d e na m e node na m e node da e m on job s ubm is s ion node jobt r a c k e r 经典版的 M a p R ed u c e 架构（ v1.0 ） ¨ 存在的问题 ¤ 单点故障：所有 J ob 由 J ob T r a c k er 调度和分配 ¤ 可扩展性： J ob T r a c k er 任务繁重 ¤ 容易出现内存溢出： T a s k T r a c k er 端，资源的分配并不考虑 C PU 、内存的 实际使用情况，而是根据任务个数分配资源 ¤ 资源分配不合理：资源被强制等量划分成多个“槽” ( Sl ot ) ， s l ot 又被进 一步划分为 M a p s l ot 和 R ed u c e s l ot ，彼此之间不能使用分配给对方的 s l ot 。 64 H a d oop v 1 . 0 v s . H a d oop v 2 . 0 65 新一代的架构设计 Y A RN （ v2.0 ） ¨ Y et A n ot h er R es ou r c e N eg ot i a t or ：另一种资源协调者。它是一个通用资源管理系 统，可为上层应用提供统一的资源管理和调度，它的引入为集群在利用率、资 源统一管理和数据共享等方面带来了巨大好处。 ¨ R es ou r c eM a n a g er ( RM ) 全局管理所有应用程序计算资源的分配，每个应用的 A p p l i c a t i on M a s t er ( AM ) 负责相应的调度和协调。 ¨ 一个应用程序无非是一个单独的传统的 M a p R ed u c e 任务或者是一个 DA G （有 向无环图）任务。 R es ou r c eM a n a g er 和每一台机器的节点管理服务器能够管理 用户在那台机器上的进程并能对计算进行组织。 66 Y A RN 设计思路 资源管理 任务调度 原JobTracker 功能 ResourceManager ApplicationMaster 原TaskTracker NodeManager 任务监控 Master端 Slave端 YARN架构思路：将原JobTacker三大功能拆分 67 Y A RN A r c h i t ec t u r e （ v2.0 ） 68 R es ou r c eM a n a g er • 处理客户端请求 • 启动 / 监控 A p p l i c a t i on M a s t er • 监控 N od eM a n a g er • 资源分配与调度 N od eM a n a g er • 单个节点上的资源管理 • 处理来自 R es ou r c eM a n g er 的命令 • 处理来自 A p p l i c a t i on M a s t er 的命令 A p p l i c a t i on M a s t er • 为应用程序申请资源，并 分配给内部任务 • 任务调度、监控与容错 C on t a i n er • 作为动态资源分配单位，每个容器中都封装了一定数 量的 C PU 、 内存、磁盘等资源，从而限定每个应用程序 可以使用的资源量。 Y A RN A r c h i t ec t u r e （ v2.0 ） 69 Y A RN ¨ 解决的问题 ¤ 更高的集群利用率，一个框架未使用的资源可由另一个框架进行使用，充 分的避免资源浪费 ¤ 在新的 Ya r n 中，通过加入 A p p l i c a t i on M a s t er 是一个可变更的部分，用户可以 针对不同的编程模型编写自己的 A p p l i c a t i on M a s t er ，让更多的编程模型运行 在 H a d oop 集群中。 ¤ 在上一版框架中， J ob T r a c k er 一个很大的负担就是监控 J ob 的 tas ks 运行情况， 现在，这个部分下放到了 A p p l i c a t i on M a s t er 中。 70 Y A RN ¨ Y A RN 的目标就是实现“ 一个集群多个框架 ”，即在一个集群上部署一个统一 的资源调度管理框架 Y A RN ， 在 Y A RN 之上可以部署其他各种计算框架。 ¨ 由 Y A RN 为这些计算框架提供统一的资源调度管理服务，并且能够根据各种计 算框架的负载需求，调整各自占用的资源，实现集群资源共享和资源弹性收缩。 ¨ 可以实现一个集群上的不同应用负载混搭，有效提高了集群的利用率。 ¨ 不同计算框架可以共享底层存储，避免了数据集跨集群移动。 71 Y A RN 72 Y A R N (C lu ster R eso u rce M an ag em en t) H D F S 2 (R ed u n d an t,R eliab le S to rag e) IN T E R A C T IV E (T ez) O N L IN E (H B a se) S T R E A M IN G (S to rm ,S 4 ,...) G R A P H (G ira p h ) In -M E M O R Y (S p a rk ) H P C M P I (O p en M P I) O T H E R (S ea rch ) (W ea v e...) B A T C H (M a p R ed u ce) 在 YA R N 上部署各种计算框架 基于 Y A RN 的 M a p R ed u c e 架构（ v2.0 ） 73 H a d oop M a p R ed u c e 基本工作过程 74 TH A NK YO U","libVersion":"0.2.4","langs":""}